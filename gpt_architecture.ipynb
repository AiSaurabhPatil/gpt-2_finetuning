{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641d8fb6",
   "metadata": {},
   "source": [
    "### Coding GPT architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53d71ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    " \"vocab_size\": 50257, # Vocabulary size\n",
    " \"context_length\": 1024, # Context length\n",
    " \"emb_dim\":768 , # Embedding dimension\n",
    " \"n_heads\": 12, # Number of attention heads\n",
    " \"n_layers\": 12, # Number of layers\n",
    " \"drop_rate\": 0.1, # Dropout rate\n",
    " \"qkv_bias\": False # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d13ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self , d_in , d_out , context_length , dropout , num_heads , qkv_bias = False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0) ,  \"d_out must be divisble by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out \n",
    "        self.num_heads = num_heads \n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in , d_out , bias = qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in , d_out , bias = qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in , d_out , bias = qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out , d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length,context_length), diagonal=1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x ): \n",
    "        b , num_tokens , d_in = x.shape # x.shape = (2,6,3)\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        # splitting the key query and value vectors to feed into multiple heads \n",
    "        \n",
    "        keys = keys.view(b,num_tokens ,self.num_heads , self.head_dim) # reshaping using view function\n",
    "        queries = queries.view(b,num_tokens ,self.num_heads , self.head_dim) \n",
    "        values = values.view(b,num_tokens ,self.num_heads , self.head_dim) \n",
    "        \n",
    "        # transposing the dimensions \n",
    "        \n",
    "        keys = keys.transpose(1,2)  #(b , self.num_heads , num_tokens , self.head_dim)\n",
    "        queries = queries.transpose(1,2)\n",
    "        values = values.transpose(1,2)\n",
    "        \n",
    "        attn_scores = queries @ keys.transpose(2,3) #(b , self.num_heads ,self_head_dim , num_tokens) \n",
    "        \n",
    "        # causal masking \n",
    "        mask_bool = self.mask.bool()[:num_tokens , :num_tokens]\n",
    "        \n",
    "        attn_scores.masked_fill_(mask_bool , -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5 , dim = -1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # calculate the context vector \n",
    "        context_vec = (attn_weights @ values).transpose(1,2)  # Tensor shape:(b, num_tokens,n_heads,head_dim)\n",
    "        \n",
    "        # combining heads into a single vector \n",
    "        context_vec = context_vec.contiguous().view(b,num_tokens,self.d_out)\n",
    "        \n",
    "        # adding the optional linear projection to transform the output into right dimension\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec\n",
    "        \n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    \n",
    "    def forward(self , x ):\n",
    "        mean = x.mean(dim = -1 , keepdim = True)\n",
    "        var = x.var(dim = -1 , keepdim = True , unbiased= False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift \n",
    "    \n",
    "\n",
    "class GELU(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self , x ):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x , 3))\n",
    "        ))\n",
    "        \n",
    "\n",
    "\n",
    "class FeedForward(nn.Module) : \n",
    "    def __init__(self, cfg ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'] , 4 * cfg['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg['emb_dim'] , cfg['emb_dim']),    )\n",
    "        \n",
    "    def forward(self, x ): \n",
    "        return self.layers(x)\n",
    "    \n",
    "    \n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,  cfg):\n",
    "        super().__init__()\n",
    "        self.attn  = MultiHeadAttention(\n",
    "            d_in = cfg['emb_dim'],\n",
    "            d_out = cfg['emb_dim'],\n",
    "            context_length= cfg['context_length'],\n",
    "            num_heads = cfg['n_heads'],\n",
    "            dropout=cfg['drop_rate'],\n",
    "            qkv_bias=cfg['qkv_bias']\n",
    "        )\n",
    "        self.ff = FeedForward(cfg=cfg)\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.drop_shortcut = nn.Dropout(cfg['drop_rate'])\n",
    "            \n",
    "    def forward(self,x):\n",
    "        shortcut = x \n",
    "        x = self.norm1(x) \n",
    "        x = self.attn(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        shortcut = x \n",
    "        x = self.norm2(x)\n",
    "        x = self. ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x \n",
    "             \n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self , cfg): \n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"] , cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg)\n",
    "              for _ in range (cfg['n_layers'])]\n",
    "        )\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"] , cfg[\"vocab_size\"] , bias = False\n",
    "        )\n",
    "        \n",
    "    def forward(self , in_idx):\n",
    "        batch_size , seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len , device = in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082e0f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "# let's test the dummy transformer by send the processing the sample data \n",
    "\n",
    "import tiktoken\n",
    " \n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "batch = [] \n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch,dim = 0 )\n",
    "print(batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fac8dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eecc620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5de9d07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "178e3b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c9533d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's  convert the prediction back to text \n",
    "\n",
    "def generate_text_simple(model , idx , max_new_token , context_size):\n",
    "    for _ in range(max_new_token):\n",
    "        idx_cond  = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        logits = logits[:,-1 ,:]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas , dim= -1 , keepdim=True)\n",
    "        idx = torch.cat((idx , idx_next),dim=1)\n",
    "\n",
    "    return idx     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00280e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 837, 314, 716]\n",
      "torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello , I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "824def5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15496,   837,   314,   716, 27018,  7283, 48443, 26012, 16560, 44407]])\n",
      "output length: 10\n"
     ]
    }
   ],
   "source": [
    "# let's generate the text \n",
    "\n",
    "model.eval() # disable the dropout layer for inference \n",
    "out = generate_text_simple(\n",
    "    model=model , \n",
    "    idx = encoded_tensor , \n",
    "    max_new_token=6, \n",
    "    context_size= GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(out)\n",
    "print(\"output length:\",len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c83e08e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello , I am Feature IT!/ Brigade incorporatedheartedly\n"
     ]
    }
   ],
   "source": [
    "decode_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4702bec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    " \"vocab_size\": 50257,\n",
    " \"context_length\": 256,\n",
    " \"emb_dim\": 768,\n",
    " \"n_heads\": 12,\n",
    " \"n_layers\": 12,\n",
    " \"drop_rate\": 0.1,\n",
    " \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64b767f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for text to token and token to text conversion\n",
    "\n",
    "def text_to_token_ids(text , tokenizer):\n",
    "    encoded = tokenizer.encode(text , allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids , tokenizer):\n",
    "    decoded_text = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "    return decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d85f62ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
      "          5308,  3398, 13174, 43071]])\n",
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model , \n",
    "    idx = text_to_token_ids(start_context,tokenizer),\n",
    "    max_new_token=10,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    "    \n",
    ")\n",
    "print(token_ids)\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bb26a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    " [40, 1107, 588]]) # \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 354 ], # [\" effort moves you\",\n",
    " [1107, 588, 11311]]) # \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5069ce2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    " logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "987751cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5900b56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort movesch really like chocolate\n",
      "Outputs batch 1:  Armed heNetflix pressuring empoweredfaith\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets.flatten(), tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"f\" {token_ids_to_text(token_ids.flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6f9f740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 3.7604e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3de76984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -10.1884, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a438e475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.5974)\n",
      "tensor(10.5974)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)\n",
    "\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5b57f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b2a2c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f10341d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5974)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional\n",
    "\n",
    "\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat , targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a39faedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(40031.1445)\n"
     ]
    }
   ],
   "source": [
    "# perplexity \n",
    "\n",
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23be02b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, 'r' , encoding=\"utf-8\") as file : \n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2aca741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n",
      "5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(total_characters)\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6180b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c5adafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "from data_prep import create_dataloader_v1\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "826cbdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    " print(x.shape, y.shape)\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    " print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa6fda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch , target_batch , model , device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1),target_batch.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93628daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss calcuation over the entire batch \n",
    "\n",
    "def calc_loss_loader(data_loader , model , device , num_batches = None):\n",
    "    total_loss = 0 \n",
    "    if len(data_loader)  == 0 :\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None: \n",
    "        num_batches = len(data_loader)\n",
    "        print(\"Length of dataloader:\",len(data_loader))\n",
    "    else:\n",
    "        num_batches = min(num_batches , len(data_loader))\n",
    "    for i , (input_batch , target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch , target_batch , model , device\n",
    "            )\n",
    "            total_loss +=loss.item()\n",
    "        else: \n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a92af1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataloader: 9\n",
      "Length of dataloader: 1\n",
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader , model , device)\n",
    "    val_loss = calc_loss_loader(val_loader , model , device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc8f8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model (model , train_loader , val_loader , device , eval_iter) : \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader , model , device , num_batches= eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader , model , device , num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss , val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "502089ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model , tokenizer , device , start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context , tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model = model , idx = encoded ,\n",
    "            max_new_token=50 , context_size = context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids , tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8f65bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the llm to reduce the loss \n",
    "def train_model_simple(model , train_loader , val_loader , optimizer, device , num_epochs,\n",
    "                       eval_freq , eval_iter , start_context , tokenizer):\n",
    "    train_losses , val_losses , track_token_seen = [] , [] ,[] \n",
    "    token_seen , global_step = 0 ,-1 \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch ,target_batch in train_loader : \n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch , target_batch ,model , device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            token_seen += input_batch.numel()\n",
    "            global_step += 1 \n",
    "\n",
    "            if global_step & eval_freq  == 0 : \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model , train_loader , val_loader , device , eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_token_seen.append(token_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                    )\n",
    "        \n",
    "        generate_and_print_sample(\n",
    "            model , tokenizer , device , start_context\n",
    "        )     \n",
    "        \n",
    "    return train_losses , val_losses , track_token_seen      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e2128ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Ep 1 (Step 000002): Train loss 8.955, Val loss 9.133\n",
      "Ep 1 (Step 000008): Train loss 7.194, Val loss 7.473\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.598, Val loss 7.052\n",
      "Ep 2 (Step 000016): Train loss 5.973, Val loss 6.561\n",
      "Every effort moves you, and, and, and, and, and, and, and, and,, and,,,,, and, and, and,, and, and,, and, and,, and, and,, and,, and\n",
      "Ep 3 (Step 000018): Train loss 5.972, Val loss 6.517\n",
      "Ep 3 (Step 000024): Train loss 5.562, Val loss 6.448\n",
      "Ep 3 (Step 000026): Train loss 5.138, Val loss 6.375\n",
      "Every effort moves you. \"I to the to the the to the to the the. I had the--I was--I to the to the to the the to the the the to the the to the to the the to the to the to the to the\n",
      "Ep 4 (Step 000032): Train loss 4.377, Val loss 6.448\n",
      "Ep 4 (Step 000034): Train loss 4.325, Val loss 6.255\n",
      "Every effort moves you know it, and he had been--and it, and I had been the.                   \"I had the, and he had the picture.   \n",
      "Ep 5 (Step 000040): Train loss 3.585, Val loss 6.258\n",
      "Ep 5 (Step 000042): Train loss 3.413, Val loss 6.241\n",
      "Every effort moves you know it was not that the picture.  \"I had the last--his-rooms--I looked up, I had always to the donkey, and I had always at the donkey. \"I looked. \"--I was his\n",
      "Ep 6 (Step 000048): Train loss 2.754, Val loss 6.202\n",
      "Ep 6 (Step 000050): Train loss 2.558, Val loss 6.232\n",
      "Every effort moves you?\" \"I that the picture. \"I told Mrs. \"Oh, and I was, in the latter about the man of the of the his eyes. \"Oh, and I had been the man of the hour. \n",
      "Ep 7 (Step 000056): Train loss 1.836, Val loss 6.273\n",
      "Ep 7 (Step 000058): Train loss 1.846, Val loss 6.297\n",
      "Every effort moves you?\" \"I that my hostess was not the fact with a little: \"Yes--and by me to me to have to see a smile behind his pictures.  \"Oh, I had the donkey. \"Oh, I was\n",
      "Ep 8 (Step 000064): Train loss 1.300, Val loss 6.302\n",
      "Ep 8 (Step 000066): Train loss 1.233, Val loss 6.350\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"I didn't _rose Dub, and threw back the head to look up at the honour being _mine_--because he's the first\n",
      "Ep 9 (Step 000072): Train loss 0.872, Val loss 6.372\n",
      "Ep 9 (Step 000074): Train loss 0.729, Val loss 6.375\n",
      "Ep 9 (Step 000080): Train loss 0.480, Val loss 6.435\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000082): Train loss 0.462, Val loss 6.475\n",
      "Ep 10 (Step 000088): Train loss 0.294, Val loss 6.605\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    " model.parameters(),\n",
    " lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    " model, train_loader, val_loader, optimizer, device,\n",
    " num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    " start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2114cc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    " fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    " ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    " ax1.plot(\n",
    " epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    " )\n",
    " ax1.set_xlabel(\"Epochs\")\n",
    " ax1.set_ylabel(\"Loss\")\n",
    " ax1.legend(loc=\"upper right\")\n",
    " ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    " ax2 = ax1.twiny()\n",
    " ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    " ax2.set_xlabel(\"Tokens seen\")\n",
    " fig.tight_layout()\n",
    " plt.show()\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "501c854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text :\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "token_ids = generate_text_simple(\n",
    "    model = model, \n",
    "    idx = text_to_token_ids(\"Every effort moves you\" , tokenizer),\n",
    "    max_new_token = 25 ,\n",
    "    context_size= GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "print(\"Output text :\\n\" , token_ids_to_text(token_ids , tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's modify the generate_text_simple by combining the temperature sampling and top-k sampling \n",
    "\n",
    "\n",
    "def generate(model, idx , max_new_tokens , context_size ,\n",
    "             temperature=0.0 , top_k =None , eos_id = None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:,-1,:]\n",
    "        \n",
    "        if top_k is not None: \n",
    "            top_logits , _ = torch.topk(logits , top_k)\n",
    "            min_val = top_logits[:,-1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val , \n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature \n",
    "            probas = torch.softmax(logits , dim = -1)\n",
    "            idx_next = torch.multinomial(probas , num_samples=1)\n",
    "        else: \n",
    "            idx_next = torch.argmax(logits , dim = -1 ,keepdim = True)\n",
    "        \n",
    "        if idx_next == eos_id : \n",
    "            break \n",
    "            \n",
    "        idx = torch.cat((idx , idx_next ),dim = 1)\n",
    "    return idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9252abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model = model , \n",
    "    idx = text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens= 20 , \n",
    "    context_size=GPT_CONFIG_124M['context_length'],\n",
    "    top_k = 5 ,\n",
    "    temperature = 0.5\n",
    "    \n",
    ") \n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da7d194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model_pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6bb663d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model_pth\",map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1ee197e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eaf33f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\",map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4 , weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55fa68b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x185d7411840>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    " \"https://raw.githubusercontent.com/rasbt/\"\n",
    " \"LLMs-from-scratch/main/ch05/\"\n",
    " \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4124d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 25.7kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:02<00:00, 482kiB/s] \n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 45.5kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [07:02<00:00, 3.36MiB/s]  \n",
      "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 5.27MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 608kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 397kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    " model_size=\"355M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3fb7430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 1024, 'n_head': 16, 'n_layer': 24}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4da4ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blocks': [{'attn': {'c_attn': {'b': array([ 6.5407079e-01, -6.4520276e-01,  1.5412229e-01, ...,\n",
      "        3.9472539e-04, -1.1913106e-03, -2.0954411e-03], dtype=float32), 'w': array([[ 0.07517347,  0.03569016, -0.0045204 , ..., -0.04698672,\n",
      "         0.01586862, -0.05079569],\n",
      "       [-0.20343858, -0.23416115, -0.12388402, ..., -0.10114633,\n",
      "         0.02333787, -0.00287042],\n",
      "       [-0.04787058, -0.20874114, -0.08843362, ...,  0.02041811,\n",
      "        -0.01904844,  0.01036439],\n",
      "       ...,\n",
      "       [ 0.01329984, -0.03209405, -0.20156056, ..., -0.02571667,\n",
      "        -0.05338867,  0.03378934],\n",
      "       [-0.43131468,  0.06190351, -0.34512466, ..., -0.03697858,\n",
      "         0.00522314, -0.00135449],\n",
      "       [ 0.4025124 ,  0.1701651 ,  0.2707895 , ..., -0.01399677,\n",
      "        -0.01223649,  0.05628034]], dtype=float32)}, 'c_proj': {'b': array([-0.00091882, -0.03253085, -0.02656874, ...,  0.0021506 ,\n",
      "        0.01144931, -0.0086791 ], dtype=float32), 'w': array([[ 0.09731582,  0.00315875,  0.03116801, ...,  0.06896061,\n",
      "        -0.04834868,  0.00774077],\n",
      "       [ 0.08741507,  0.03742109,  0.00523562, ...,  0.00361189,\n",
      "        -0.01518497, -0.09358007],\n",
      "       [ 0.02852689, -0.01206294,  0.0026515 , ..., -0.02021747,\n",
      "        -0.02933314, -0.03988229],\n",
      "       ...,\n",
      "       [-0.01651173,  0.0486601 , -0.0183733 , ..., -0.04045309,\n",
      "        -0.00726338, -0.01555256],\n",
      "       [ 0.0102531 , -0.02114974,  0.01307088, ..., -0.0297845 ,\n",
      "        -0.02007058,  0.03976598],\n",
      "       [ 0.04024382, -0.01942073, -0.01854474, ..., -0.02530159,\n",
      "         0.00601882,  0.03062136]], dtype=float32)}}, 'ln_1': {'b': array([ 0.01300852,  0.00294004,  0.02314591, ..., -0.00490678,\n",
      "        0.02039295,  0.00718479], dtype=float32), 'g': array([0.06128939, 0.05613279, 0.05076449, ..., 0.05598325, 0.03891658,\n",
      "       0.05972508], dtype=float32)}, 'ln_2': {'b': array([ 0.0898256 ,  0.06765975,  0.04593471, ..., -0.09400566,\n",
      "        0.06674176, -0.0326697 ], dtype=float32), 'g': array([0.1978072 , 0.22313562, 0.2235109 , ..., 0.22109915, 0.20564112,\n",
      "       0.23654416], dtype=float32)}, 'mlp': {'c_fc': {'b': array([ 0.00030897, -0.0365757 , -0.1258011 , ...,  0.08479553,\n",
      "       -0.09030025,  0.00784311], dtype=float32), 'w': array([[-0.16075155, -0.11744232, -0.03249313, ..., -0.03635079,\n",
      "        -0.14788425, -0.1326774 ],\n",
      "       [-0.15331613, -0.02559521, -0.14100766, ...,  0.0393893 ,\n",
      "        -0.10712375, -0.1278759 ],\n",
      "       [-0.03548624, -0.12841651,  0.09356113, ...,  0.11177705,\n",
      "         0.10400506, -0.0916307 ],\n",
      "       ...,\n",
      "       [ 0.03051916,  0.03644074,  0.22361481, ...,  0.07117081,\n",
      "         0.08624196,  0.12571983],\n",
      "       [-0.06671792,  0.14396259,  0.05205442, ...,  0.12147691,\n",
      "        -0.07717369, -0.11750457],\n",
      "       [-0.14989236,  0.07495388,  0.17222755, ...,  0.07518341,\n",
      "         0.00173183,  0.02601216]], dtype=float32)}, 'c_proj': {'b': array([-0.01752129,  0.06625497, -0.01099529, ..., -0.19136392,\n",
      "       -0.14624879, -0.03276237], dtype=float32), 'w': array([[ 0.00810163,  0.03885144,  0.04732665, ...,  0.02942911,\n",
      "         0.01381911,  0.08152894],\n",
      "       [-0.07641982, -0.05481247,  0.10279528, ..., -0.01548585,\n",
      "         0.08287325, -0.03819284],\n",
      "       [ 0.0076111 , -0.02002922,  0.18790399, ..., -0.03194067,\n",
      "         0.04381916,  0.04294832],\n",
      "       ...,\n",
      "       [-0.1135599 , -0.14550965, -0.09461147, ..., -0.16540246,\n",
      "        -0.02156007,  0.05590659],\n",
      "       [-0.041156  ,  0.04632522,  0.14721952, ...,  0.11454222,\n",
      "        -0.02494736,  0.13027741],\n",
      "       [-0.00360533,  0.04154442, -0.01159863, ..., -0.01311528,\n",
      "         0.04212309,  0.01807038]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.30244848, -0.05497394, -0.04107467, ..., -0.03945614,\n",
      "        0.05738121,  0.00661783], dtype=float32), 'w': array([[ 0.03005726,  0.03588421,  0.02364527, ...,  0.10690686,\n",
      "        -0.00774311,  0.11960573],\n",
      "       [ 0.03999247,  0.0143177 , -0.0017319 , ...,  0.01750309,\n",
      "        -0.05786258, -0.01862851],\n",
      "       [-0.01235726, -0.01218007, -0.13283822, ..., -0.12058125,\n",
      "        -0.0209273 ,  0.00928254],\n",
      "       ...,\n",
      "       [-0.09964556,  0.07504308,  0.02911813, ..., -0.0037637 ,\n",
      "        -0.02503887, -0.0429374 ],\n",
      "       [-0.00747078,  0.06924867,  0.01477381, ...,  0.1186597 ,\n",
      "         0.06835363,  0.06223528],\n",
      "       [-0.01995672,  0.02849435,  0.01857417, ...,  0.03000623,\n",
      "        -0.01622108,  0.01748101]], dtype=float32)}, 'c_proj': {'b': array([ 0.10221897,  0.11507016,  0.0758692 , ..., -0.20227176,\n",
      "       -0.21943384,  0.13335392], dtype=float32), 'w': array([[ 0.03154327,  0.01261129,  0.02442785, ..., -0.01978105,\n",
      "        -0.02119048,  0.01161148],\n",
      "       [-0.03823494, -0.01217618, -0.03336376, ..., -0.01641783,\n",
      "        -0.03493026, -0.00907144],\n",
      "       [-0.05110988, -0.03022887, -0.04082032, ...,  0.08581869,\n",
      "         0.04222849, -0.10546774],\n",
      "       ...,\n",
      "       [-0.00325638,  0.04887965, -0.02693886, ...,  0.05946285,\n",
      "        -0.02818602,  0.01370916],\n",
      "       [ 0.07815131,  0.09287825,  0.00100407, ..., -0.03700785,\n",
      "        -0.10655867, -0.03479441],\n",
      "       [-0.05564928, -0.00104871,  0.01282815, ..., -0.04819549,\n",
      "        -0.1144071 , -0.02398132]], dtype=float32)}}, 'ln_1': {'b': array([-0.00726151, -0.02203468, -0.00734562, ...,  0.00106865,\n",
      "       -0.00882803, -0.00596746], dtype=float32), 'g': array([0.3696786 , 0.36671597, 0.28570384, ..., 0.38097855, 0.3758777 ,\n",
      "       0.35875133], dtype=float32)}, 'ln_2': {'b': array([-0.01186949, -0.01497437, -0.00721223, ..., -0.01489491,\n",
      "       -0.04123953, -0.0132851 ], dtype=float32), 'g': array([0.367664  , 0.39159417, 0.31370106, ..., 0.4189234 , 0.4567223 ,\n",
      "       0.37998948], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.08768283, -0.03053857, -0.00027054, ...,  0.00814079,\n",
      "        0.05951592, -0.07845309], dtype=float32), 'w': array([[-0.19492197,  0.05825282, -0.2536039 , ...,  0.11786618,\n",
      "         0.03009634, -0.01146251],\n",
      "       [ 0.03059434, -0.10987071, -0.10718859, ...,  0.07440125,\n",
      "         0.01357609,  0.0290325 ],\n",
      "       [-0.00729635, -0.00279507,  0.16857798, ..., -0.01595885,\n",
      "        -0.09697828, -0.01987751],\n",
      "       ...,\n",
      "       [ 0.08647926,  0.10441668, -0.03259671, ..., -0.05217944,\n",
      "         0.02211567,  0.04879996],\n",
      "       [-0.0577841 , -0.07103078,  0.0781072 , ...,  0.06986717,\n",
      "         0.12708847,  0.01342489],\n",
      "       [ 0.09621616,  0.14945985,  0.14809138, ..., -0.01507991,\n",
      "         0.02483109, -0.02766807]], dtype=float32)}, 'c_proj': {'b': array([-0.06817133,  0.01799958,  0.06648435, ..., -0.10430706,\n",
      "       -0.08369613, -0.05077686], dtype=float32), 'w': array([[-1.28430307e-01,  1.98568944e-02, -4.34267968e-02, ...,\n",
      "        -1.04222074e-01, -1.08101644e-01, -1.41581167e-02],\n",
      "       [-7.88804889e-02,  3.64495404e-02, -5.49757406e-02, ...,\n",
      "        -5.24870083e-02,  2.42168065e-02, -4.55845222e-02],\n",
      "       [-1.46076784e-01,  7.46988356e-02,  6.79184049e-02, ...,\n",
      "        -3.29639986e-02,  8.12807605e-02,  1.26469597e-01],\n",
      "       ...,\n",
      "       [-3.47079560e-02, -5.35583757e-02,  1.34371752e-02, ...,\n",
      "        -2.89109852e-02, -5.24042398e-02,  2.36092620e-02],\n",
      "       [-8.55709240e-02, -5.98179474e-02,  1.17709577e-01, ...,\n",
      "         2.68367771e-02, -1.83593649e-02, -5.93444183e-02],\n",
      "       [-2.79843267e-02, -7.21272430e-04, -2.27804724e-02, ...,\n",
      "         2.28163608e-05,  3.78500810e-03,  2.19015349e-02]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([-0.21188207, -0.03618144, -0.21806802, ..., -0.0034988 ,\n",
      "       -0.0096161 , -0.01289122], dtype=float32), 'w': array([[ 0.09610663, -0.01038623,  0.02515893, ..., -0.10075827,\n",
      "        -0.00950994,  0.02353378],\n",
      "       [ 0.04345391, -0.06139218, -0.00882558, ...,  0.02625427,\n",
      "        -0.05090388,  0.00755797],\n",
      "       [-0.022645  , -0.00536318,  0.03390682, ..., -0.20892783,\n",
      "        -0.02509835,  0.13550587],\n",
      "       ...,\n",
      "       [ 0.03473561, -0.02876116, -0.00401303, ..., -0.0009402 ,\n",
      "         0.1962825 , -0.072978  ],\n",
      "       [ 0.02297842, -0.03410781, -0.01042172, ..., -0.0123946 ,\n",
      "        -0.11376853, -0.05000713],\n",
      "       [ 0.01874618,  0.01381156, -0.02745019, ...,  0.12421932,\n",
      "        -0.04987535,  0.19635153]], dtype=float32)}, 'c_proj': {'b': array([ 0.0047797 ,  0.15081818,  0.08775654, ...,  0.12722051,\n",
      "       -0.10071407,  0.19814397], dtype=float32), 'w': array([[-0.05396831, -0.03782104, -0.04693634, ..., -0.03728767,\n",
      "        -0.03967508, -0.0156362 ],\n",
      "       [ 0.01072109, -0.0161328 , -0.05252416, ..., -0.03699934,\n",
      "        -0.01058839,  0.04375967],\n",
      "       [-0.02646129, -0.02024629, -0.00060829, ..., -0.01878783,\n",
      "         0.06091768, -0.01586957],\n",
      "       ...,\n",
      "       [-0.17527357,  0.03011186, -0.07421632, ..., -0.02600587,\n",
      "         0.01103395,  0.05235411],\n",
      "       [-0.06277514,  0.00228235, -0.01687126, ..., -0.02894737,\n",
      "         0.0274603 ,  0.01595962],\n",
      "       [-0.07879918, -0.00139586,  0.01330421, ...,  0.09731264,\n",
      "         0.02348994, -0.03847166]], dtype=float32)}}, 'ln_1': {'b': array([ 0.00275605, -0.01216119, -0.00992011, ...,  0.00448388,\n",
      "       -0.00347645, -0.00714422], dtype=float32), 'g': array([0.29198936, 0.29475394, 0.23141845, ..., 0.32528123, 0.34415895,\n",
      "       0.29995582], dtype=float32)}, 'ln_2': {'b': array([-0.00955786, -0.0087732 ,  0.00477561, ..., -0.02372817,\n",
      "       -0.02198504, -0.02315852], dtype=float32), 'g': array([0.43380237, 0.46618634, 0.38405934, ..., 0.4735834 , 0.4931558 ,\n",
      "       0.44269183], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.14089698,  0.01987203, -0.13922603, ...,  0.00451457,\n",
      "       -0.03548068, -0.0282312 ], dtype=float32), 'w': array([[ 0.11051881, -0.02826927, -0.0776857 , ...,  0.16389515,\n",
      "        -0.0481879 , -0.10536621],\n",
      "       [ 0.04328204, -0.17658742, -0.09327331, ...,  0.07473135,\n",
      "         0.07807542,  0.08401838],\n",
      "       [ 0.25560316,  0.03218169, -0.17231156, ..., -0.05303396,\n",
      "         0.0706458 ,  0.06952778],\n",
      "       ...,\n",
      "       [-0.05498162,  0.23323278,  0.06481132, ..., -0.07686617,\n",
      "        -0.09424449, -0.09686827],\n",
      "       [ 0.00865282,  0.13937066,  0.08141177, ...,  0.0673202 ,\n",
      "        -0.07311082, -0.05347271],\n",
      "       [ 0.10320938, -0.0335859 ,  0.03456526, ..., -0.07576574,\n",
      "         0.17925705,  0.09629233]], dtype=float32)}, 'c_proj': {'b': array([-0.08690756,  0.00014453,  0.12162385, ..., -0.05095162,\n",
      "        0.01348234, -0.04258446], dtype=float32), 'w': array([[ 0.01386676,  0.15046148,  0.14981015, ..., -0.01690154,\n",
      "        -0.09282388, -0.04258538],\n",
      "       [ 0.01761436,  0.09199844, -0.07762388, ..., -0.01559291,\n",
      "        -0.01681101, -0.02112409],\n",
      "       [-0.11703149, -0.0499415 , -0.08894324, ..., -0.05792133,\n",
      "        -0.06005617,  0.18257868],\n",
      "       ...,\n",
      "       [-0.07676468, -0.06109289,  0.03781684, ...,  0.05557456,\n",
      "         0.01769488,  0.0652787 ],\n",
      "       [ 0.04464386, -0.07243676, -0.01576702, ...,  0.01581907,\n",
      "         0.09930567, -0.14441551],\n",
      "       [ 0.0718787 , -0.07366755,  0.0104518 , ...,  0.03242326,\n",
      "         0.09995396, -0.1176237 ]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([-1.3122612e-01,  3.4269977e-02,  2.4782728e-02, ...,\n",
      "        6.2836865e-05, -2.2262650e-02,  1.4191027e-02], dtype=float32), 'w': array([[-0.16676895,  0.03596115,  0.08457376, ..., -0.01620425,\n",
      "         0.01285785,  0.03888176],\n",
      "       [-0.0173636 ,  0.06422385,  0.13086456, ..., -0.01388493,\n",
      "        -0.00047568, -0.08134317],\n",
      "       [-0.27897647, -0.08683112,  0.0858673 , ..., -0.01979538,\n",
      "         0.00851037, -0.02611488],\n",
      "       ...,\n",
      "       [-0.02841551,  0.04601737,  0.05045171, ..., -0.0669157 ,\n",
      "         0.06317145,  0.06106897],\n",
      "       [-0.06927624, -0.16143578,  0.03531529, ..., -0.00859316,\n",
      "         0.05148862,  0.09850761],\n",
      "       [ 0.02486607,  0.0787454 ,  0.13245863, ...,  0.08281499,\n",
      "         0.01821467,  0.13108166]], dtype=float32)}, 'c_proj': {'b': array([0.02031248, 0.07249939, 0.07901268, ..., 0.17861839, 0.01602402,\n",
      "       0.11611698], dtype=float32), 'w': array([[ 0.01561736,  0.0936243 ,  0.09611712, ...,  0.03452617,\n",
      "        -0.01350647,  0.08283217],\n",
      "       [ 0.12280437, -0.01770051, -0.04500638, ...,  0.06199577,\n",
      "         0.04565681, -0.13309242],\n",
      "       [ 0.01545161,  0.10976674,  0.10739459, ..., -0.04865584,\n",
      "         0.07769982,  0.03899084],\n",
      "       ...,\n",
      "       [-0.03576174, -0.05398738,  0.0624796 , ...,  0.02386071,\n",
      "         0.03257561, -0.02419167],\n",
      "       [ 0.0577633 , -0.03163616, -0.05868566, ..., -0.0068397 ,\n",
      "        -0.05522885, -0.04092003],\n",
      "       [-0.07772385, -0.00643981,  0.06043429, ...,  0.02976912,\n",
      "         0.00505821,  0.04723685]], dtype=float32)}}, 'ln_1': {'b': array([ 0.00358192, -0.01019321, -0.01287272, ...,  0.00910698,\n",
      "        0.00721679,  0.00079245], dtype=float32), 'g': array([0.35098642, 0.37311882, 0.29654652, ..., 0.404409  , 0.37689346,\n",
      "       0.36091763], dtype=float32)}, 'ln_2': {'b': array([-0.00623849, -0.01795677,  0.01361916, ..., -0.01346319,\n",
      "        0.02020144, -0.02228164], dtype=float32), 'g': array([0.515453  , 0.54090875, 0.45213544, ..., 0.54843193, 0.5012714 ,\n",
      "       0.50972223], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.03098353, -0.20269375, -0.11239219, ..., -0.09703261,\n",
      "       -0.08675219, -0.1270045 ], dtype=float32), 'w': array([[ 0.00220424, -0.067881  , -0.07952493, ...,  0.17821294,\n",
      "        -0.00998734,  0.0498693 ],\n",
      "       [-0.06174042, -0.04790047, -0.07259727, ..., -0.06088321,\n",
      "         0.03529944,  0.02424461],\n",
      "       [ 0.02453986,  0.04943795,  0.06984738, ...,  0.0829265 ,\n",
      "        -0.05311944, -0.00937481],\n",
      "       ...,\n",
      "       [ 0.00446025, -0.15797687,  0.02502711, ...,  0.20169541,\n",
      "        -0.03956321, -0.00630735],\n",
      "       [ 0.02839428, -0.17347983,  0.02084345, ...,  0.09270673,\n",
      "         0.05124737,  0.10093509],\n",
      "       [-0.07105475,  0.00308318, -0.01041518, ..., -0.04987955,\n",
      "        -0.04436513,  0.00807048]], dtype=float32)}, 'c_proj': {'b': array([-0.08784848, -0.00503069,  0.07297502, ..., -0.06417707,\n",
      "       -0.07288951, -0.09324101], dtype=float32), 'w': array([[-0.0308348 ,  0.03313038, -0.02585563, ...,  0.00505924,\n",
      "        -0.08379139,  0.13981555],\n",
      "       [ 0.08984987,  0.11856978, -0.0448392 , ...,  0.09284967,\n",
      "        -0.01869497, -0.04158947],\n",
      "       [ 0.10625722,  0.07856289,  0.14966151, ..., -0.05303862,\n",
      "         0.0063859 , -0.08688842],\n",
      "       ...,\n",
      "       [-0.02907947,  0.04449933, -0.13562664, ..., -0.12839748,\n",
      "         0.0377156 , -0.0269764 ],\n",
      "       [-0.14629713,  0.04326042, -0.09197345, ...,  0.12983626,\n",
      "         0.07067076, -0.04982404],\n",
      "       [-0.06159092,  0.02641423,  0.0362253 , ...,  0.0035263 ,\n",
      "        -0.09442484,  0.08965474]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.03113791,  0.18108681,  0.01565261, ...,  0.01733791,\n",
      "       -0.01364   ,  0.00144826], dtype=float32), 'w': array([[-0.18259805, -0.0542073 , -0.35039204, ...,  0.11190932,\n",
      "         0.14631923, -0.07893483],\n",
      "       [ 0.0712902 , -0.01845826, -0.06067565, ...,  0.18368493,\n",
      "         0.04514475, -0.22637886],\n",
      "       [ 0.16704026,  0.19365785, -0.12589496, ...,  0.1040839 ,\n",
      "         0.03900462,  0.01273714],\n",
      "       ...,\n",
      "       [ 0.1101584 ,  0.09586065,  0.09516901, ..., -0.16920508,\n",
      "        -0.03646703,  0.02589336],\n",
      "       [ 0.11621783, -0.11791377, -0.04797451, ..., -0.16651645,\n",
      "         0.18568935, -0.09738221],\n",
      "       [-0.2517855 , -0.01504135, -0.04463797, ...,  0.1834346 ,\n",
      "        -0.06841256,  0.19143055]], dtype=float32)}, 'c_proj': {'b': array([ 0.00413443, -0.02941114,  0.04881532, ...,  0.10933574,\n",
      "       -0.00952554,  0.04335452], dtype=float32), 'w': array([[ 0.03767079,  0.00028906, -0.09137218, ...,  0.05876534,\n",
      "        -0.08834802,  0.03786865],\n",
      "       [-0.03890928, -0.023879  , -0.04371391, ..., -0.08317997,\n",
      "         0.03309564,  0.1135775 ],\n",
      "       [-0.02911399, -0.10220361,  0.00634813, ..., -0.12781066,\n",
      "        -0.03395214, -0.021648  ],\n",
      "       ...,\n",
      "       [-0.04340944, -0.02030148,  0.03835498, ...,  0.06471489,\n",
      "        -0.01738714, -0.00530477],\n",
      "       [-0.06263939, -0.08329644, -0.00535864, ...,  0.00887008,\n",
      "        -0.03098604,  0.01759921],\n",
      "       [ 0.16736287,  0.05585375, -0.10061049, ..., -0.09363437,\n",
      "        -0.03331734, -0.17478232]], dtype=float32)}}, 'ln_1': {'b': array([-0.00425032, -0.01666398, -0.01244045, ...,  0.00640718,\n",
      "        0.0049342 , -0.00754647], dtype=float32), 'g': array([0.4921032 , 0.49499726, 0.40927112, ..., 0.49863392, 0.50159675,\n",
      "       0.4706413 ], dtype=float32)}, 'ln_2': {'b': array([-0.03406186, -0.03208644,  0.0209011 , ..., -0.04469365,\n",
      "       -0.00152015, -0.01983943], dtype=float32), 'g': array([0.5268485, 0.540721 , 0.4559919, ..., 0.5724245, 0.540964 ,\n",
      "       0.5097647], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.10895324, -0.05950551, -0.0870075 , ..., -0.1034155 ,\n",
      "       -0.10290038, -0.05724692], dtype=float32), 'w': array([[ 0.03150328,  0.27298832, -0.05083681, ...,  0.02560595,\n",
      "        -0.0159169 ,  0.16082546],\n",
      "       [-0.04783859,  0.153351  ,  0.1577137 , ...,  0.02121481,\n",
      "         0.07176864, -0.17127153],\n",
      "       [-0.04440791,  0.12728384, -0.08373536, ...,  0.09208312,\n",
      "         0.14225374, -0.11090629],\n",
      "       ...,\n",
      "       [ 0.02339103, -0.05557343,  0.10260369, ..., -0.02220326,\n",
      "         0.12040024,  0.2020839 ],\n",
      "       [-0.11957653, -0.02810336, -0.03183748, ...,  0.16585408,\n",
      "        -0.15881515, -0.04455364],\n",
      "       [ 0.00403579,  0.04969375,  0.07422091, ...,  0.00230661,\n",
      "        -0.03755563,  0.04843258]], dtype=float32)}, 'c_proj': {'b': array([-0.11507278, -0.02838614,  0.06330016, ..., -0.04948343,\n",
      "       -0.21362743, -0.00778005], dtype=float32), 'w': array([[ 0.05483134, -0.00232383,  0.08761322, ...,  0.01689244,\n",
      "         0.10779819, -0.166972  ],\n",
      "       [-0.20574294, -0.09279068, -0.16366209, ...,  0.02488738,\n",
      "         0.0196054 , -0.04845046],\n",
      "       [ 0.23999932, -0.15556161,  0.03004351, ...,  0.04930829,\n",
      "         0.00829073,  0.12133674],\n",
      "       ...,\n",
      "       [ 0.00072282,  0.12064762, -0.11996224, ...,  0.02098159,\n",
      "         0.23394343, -0.0310121 ],\n",
      "       [-0.02711555,  0.02967799,  0.00594035, ..., -0.05000487,\n",
      "        -0.03821465, -0.05471869],\n",
      "       [ 0.02747687, -0.02156127, -0.08887883, ..., -0.00655335,\n",
      "         0.059528  , -0.0851764 ]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([-0.00883793,  0.13652404, -0.05852421, ...,  0.04828221,\n",
      "        0.01917001, -0.035065  ], dtype=float32), 'w': array([[ 0.01856929, -0.08968838, -0.07044583, ..., -0.09776461,\n",
      "        -0.01988314, -0.04781651],\n",
      "       [-0.25472897,  0.11986386, -0.12738934, ...,  0.16390131,\n",
      "        -0.14226907, -0.05194677],\n",
      "       [-0.01320406,  0.11372096,  0.03270294, ...,  0.01120894,\n",
      "         0.01073571, -0.0455219 ],\n",
      "       ...,\n",
      "       [-0.04926801, -0.0276565 ,  0.10020884, ..., -0.02236271,\n",
      "        -0.07033411, -0.0692285 ],\n",
      "       [ 0.19550174,  0.03059881, -0.15221503, ..., -0.01671548,\n",
      "        -0.14132914, -0.00424239],\n",
      "       [-0.15770154,  0.04739571, -0.01625605, ...,  0.13782758,\n",
      "        -0.03019779, -0.03686737]], dtype=float32)}, 'c_proj': {'b': array([-0.04167743,  0.04226952,  0.03745371, ...,  0.15579522,\n",
      "        0.0684458 , -0.06578127], dtype=float32), 'w': array([[ 0.07424952,  0.20519696, -0.00654496, ..., -0.05656828,\n",
      "        -0.05920241, -0.01645795],\n",
      "       [-0.03701721,  0.04565428,  0.06943785, ..., -0.01858267,\n",
      "        -0.05690886, -0.03696539],\n",
      "       [-0.09637503,  0.05477154,  0.04951239, ...,  0.18791905,\n",
      "         0.08743197,  0.05123796],\n",
      "       ...,\n",
      "       [-0.0792108 ,  0.0617758 , -0.0314924 , ..., -0.05654255,\n",
      "         0.07615755, -0.06355911],\n",
      "       [ 0.09901214, -0.07607632,  0.08388631, ...,  0.04210205,\n",
      "        -0.09436001,  0.00149587],\n",
      "       [ 0.03122887,  0.04709696, -0.05904511, ...,  0.02688668,\n",
      "        -0.08054794,  0.04477125]], dtype=float32)}}, 'ln_1': {'b': array([-0.00661268, -0.02334093, -0.01349361, ..., -0.00131243,\n",
      "       -0.00068404, -0.00891718], dtype=float32), 'g': array([0.51370233, 0.53334314, 0.44142357, ..., 0.52930945, 0.55306983,\n",
      "       0.505951  ], dtype=float32)}, 'ln_2': {'b': array([-0.01341575, -0.03794958,  0.02696176, ..., -0.02597098,\n",
      "       -0.00936458,  0.00411097], dtype=float32), 'g': array([0.48730704, 0.5199244 , 0.44937614, ..., 0.52794933, 0.52413607,\n",
      "       0.49124312], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.05171406, -0.09625429, -0.12122255, ..., -0.07117468,\n",
      "       -0.10394197, -0.02854035], dtype=float32), 'w': array([[-0.05249016,  0.04654034, -0.01985274, ..., -0.00330726,\n",
      "        -0.17945445, -0.06944752],\n",
      "       [ 0.06904658, -0.14086074, -0.09250937, ...,  0.09225497,\n",
      "         0.13135105,  0.05443429],\n",
      "       [ 0.10322028,  0.20629208,  0.12354515, ..., -0.04488059,\n",
      "         0.05541405, -0.11137623],\n",
      "       ...,\n",
      "       [ 0.07908205, -0.19399482, -0.08236578, ...,  0.09971427,\n",
      "         0.06157342,  0.17187831],\n",
      "       [ 0.01546767,  0.14760886,  0.11728764, ..., -0.13642627,\n",
      "         0.00363884,  0.01281507],\n",
      "       [ 0.10096388, -0.13949928, -0.18371777, ...,  0.09966923,\n",
      "         0.06169066, -0.3143763 ]], dtype=float32)}, 'c_proj': {'b': array([-0.07728362, -0.02134798, -0.02051459, ..., -0.06854204,\n",
      "       -0.23760012,  0.02862337], dtype=float32), 'w': array([[ 0.01035514,  0.02827455,  0.03355332, ..., -0.00796591,\n",
      "         0.01326122,  0.04075503],\n",
      "       [ 0.02121864,  0.0052227 ,  0.1066641 , ..., -0.1152484 ,\n",
      "         0.02580874, -0.00493442],\n",
      "       [-0.20876318,  0.07054667,  0.12047185, ...,  0.11365111,\n",
      "         0.00553796, -0.19119136],\n",
      "       ...,\n",
      "       [ 0.05099154, -0.11838485, -0.03700661, ..., -0.00458502,\n",
      "         0.04179738, -0.00983339],\n",
      "       [-0.04077752, -0.076912  ,  0.01537318, ...,  0.04102529,\n",
      "        -0.07702177, -0.02047684],\n",
      "       [ 0.00732931,  0.07740576,  0.1574716 , ..., -0.04911741,\n",
      "         0.06003641,  0.12471015]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.04559273,  0.05899708,  0.01820972, ...,  0.01779578,\n",
      "        0.00279433, -0.01192534], dtype=float32), 'w': array([[ 0.07954741, -0.02481511,  0.04601479, ...,  0.04183543,\n",
      "         0.04805915, -0.09374943],\n",
      "       [-0.13238887, -0.13387904, -0.03046681, ...,  0.0101571 ,\n",
      "        -0.10343715,  0.0062729 ],\n",
      "       [ 0.00548726,  0.05676394,  0.12041113, ...,  0.07318599,\n",
      "        -0.13990763, -0.10557189],\n",
      "       ...,\n",
      "       [-0.08260117,  0.04570131,  0.05323411, ..., -0.02171398,\n",
      "        -0.06513645,  0.12672485],\n",
      "       [-0.11386221,  0.07139178,  0.02876328, ..., -0.00835092,\n",
      "         0.03440734,  0.11176647],\n",
      "       [ 0.13551183, -0.12225655,  0.04798707, ...,  0.00434992,\n",
      "         0.01191073,  0.09206912]], dtype=float32)}, 'c_proj': {'b': array([-0.09700087, -0.05333071, -0.00532838, ...,  0.08614724,\n",
      "        0.0803827 , -0.09960822], dtype=float32), 'w': array([[ 0.02617427,  0.12863268, -0.03196152, ...,  0.11979769,\n",
      "        -0.00672796,  0.09718335],\n",
      "       [ 0.01120535,  0.0411936 , -0.08770464, ..., -0.04715959,\n",
      "         0.15969342,  0.03292856],\n",
      "       [-0.16871178,  0.13762535,  0.08640654, ..., -0.11613933,\n",
      "        -0.03043744,  0.045339  ],\n",
      "       ...,\n",
      "       [-0.00385849, -0.01617603, -0.01748884, ...,  0.02674766,\n",
      "        -0.02777272,  0.07509501],\n",
      "       [ 0.02493843, -0.08108558, -0.06593118, ..., -0.01465045,\n",
      "         0.01231076, -0.02073702],\n",
      "       [-0.00053094,  0.03092293, -0.00980578, ...,  0.00805333,\n",
      "        -0.001546  , -0.14031872]], dtype=float32)}}, 'ln_1': {'b': array([-0.01040937, -0.02090507, -0.0197124 , ..., -0.00190272,\n",
      "       -0.01357757, -0.0188606 ], dtype=float32), 'g': array([0.564848  , 0.5566369 , 0.48226872, ..., 0.59162384, 0.5996484 ,\n",
      "       0.54653984], dtype=float32)}, 'ln_2': {'b': array([-0.01610468, -0.0202017 ,  0.01884433, ..., -0.02272613,\n",
      "       -0.0085976 ,  0.02251354], dtype=float32), 'g': array([0.47949326, 0.50183576, 0.45206687, ..., 0.5309042 , 0.5239965 ,\n",
      "       0.50878894], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.12501118, -0.06991541, -0.05007854, ..., -0.08278238,\n",
      "        0.00810171, -0.00488196], dtype=float32), 'w': array([[-0.01460225,  0.11920062,  0.19400956, ...,  0.0906258 ,\n",
      "        -0.22359756, -0.03631084],\n",
      "       [-0.22754282,  0.1992715 ,  0.00499172, ..., -0.21481495,\n",
      "        -0.20880109,  0.02627896],\n",
      "       [ 0.13687658,  0.05230059,  0.03675741, ..., -0.10321071,\n",
      "        -0.01737838, -0.00068784],\n",
      "       ...,\n",
      "       [ 0.10858378, -0.11073788,  0.00926953, ...,  0.04374954,\n",
      "        -0.08786061, -0.05144383],\n",
      "       [-0.01368233,  0.16571829, -0.03568784, ...,  0.16476405,\n",
      "        -0.01129228, -0.142756  ],\n",
      "       [-0.04764958,  0.08228415, -0.09329361, ..., -0.20447259,\n",
      "         0.05872304, -0.03249722]], dtype=float32)}, 'c_proj': {'b': array([-0.01696123,  0.07923701,  0.02820353, ..., -0.03179617,\n",
      "       -0.25598025,  0.01387371], dtype=float32), 'w': array([[-0.08493933, -0.09039157,  0.04688799, ..., -0.07648282,\n",
      "        -0.13738894, -0.06402728],\n",
      "       [ 0.06436298,  0.03587134, -0.00458277, ..., -0.06266855,\n",
      "         0.01445309,  0.08483884],\n",
      "       [-0.11327084, -0.01056408,  0.07852967, ..., -0.05622638,\n",
      "         0.15188763, -0.07421883],\n",
      "       ...,\n",
      "       [ 0.09033472,  0.14231499, -0.03757137, ...,  0.08687382,\n",
      "         0.11625659, -0.14645864],\n",
      "       [ 0.11680246, -0.00428188,  0.0411982 , ..., -0.05960582,\n",
      "        -0.03740543,  0.00739588],\n",
      "       [-0.01362864,  0.08094585, -0.08136269, ..., -0.01854511,\n",
      "         0.15387562, -0.00601781]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([-0.12679422, -0.03997169, -0.05789072, ...,  0.00327873,\n",
      "       -0.00340021,  0.00093996], dtype=float32), 'w': array([[-0.1656464 ,  0.15542632, -0.1579398 , ..., -0.09501697,\n",
      "        -0.05854004, -0.11453348],\n",
      "       [-0.15118958,  0.05851636,  0.04797763, ..., -0.08562769,\n",
      "         0.02027836,  0.05299002],\n",
      "       [-0.23062101, -0.02371277, -0.01312227, ...,  0.0124329 ,\n",
      "         0.08531732,  0.12570386],\n",
      "       ...,\n",
      "       [-0.00116208, -0.06726769,  0.10038704, ..., -0.02862098,\n",
      "        -0.1001206 ,  0.03860517],\n",
      "       [ 0.10351787, -0.11778189,  0.06546692, ..., -0.02310997,\n",
      "        -0.03414207,  0.02113096],\n",
      "       [-0.03821316, -0.01097251,  0.00216515, ..., -0.04443832,\n",
      "        -0.15184344, -0.0647137 ]], dtype=float32)}, 'c_proj': {'b': array([ 0.02962922, -0.0965017 , -0.01173404, ..., -0.03461358,\n",
      "        0.09195539, -0.07957795], dtype=float32), 'w': array([[ 0.14038233, -0.05019546, -0.10936854, ..., -0.06178946,\n",
      "        -0.2178272 ,  0.0787894 ],\n",
      "       [ 0.01796793, -0.18604666,  0.03472443, ...,  0.0343232 ,\n",
      "        -0.19218028, -0.02848245],\n",
      "       [-0.08107083, -0.03891877,  0.09196159, ..., -0.01741631,\n",
      "         0.00201957, -0.07881384],\n",
      "       ...,\n",
      "       [ 0.06538665,  0.07183105,  0.02951619, ...,  0.04021668,\n",
      "         0.10077074, -0.07573627],\n",
      "       [-0.1257755 , -0.10694812, -0.10225644, ..., -0.1598728 ,\n",
      "        -0.04150413,  0.05302456],\n",
      "       [ 0.09734061,  0.11905193, -0.11149649, ..., -0.08095567,\n",
      "         0.05566338, -0.09358196]], dtype=float32)}}, 'ln_1': {'b': array([-0.01047603, -0.02391141, -0.02276636, ..., -0.00960562,\n",
      "       -0.00994515, -0.01517156], dtype=float32), 'g': array([0.54243934, 0.56528497, 0.49075508, ..., 0.5722441 , 0.6074042 ,\n",
      "       0.5371045 ], dtype=float32)}, 'ln_2': {'b': array([-0.02032136,  0.00130577,  0.01832599, ..., -0.0094071 ,\n",
      "        0.00106701,  0.01976454], dtype=float32), 'g': array([0.48140568, 0.52465296, 0.43664002, ..., 0.52196   , 0.5056345 ,\n",
      "       0.5041306 ], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.04918155,  0.03842362, -0.09306417, ..., -0.02565707,\n",
      "       -0.02440855, -0.08661579], dtype=float32), 'w': array([[ 0.04598751, -0.11551082,  0.0634094 , ..., -0.05072504,\n",
      "         0.00368486, -0.16676164],\n",
      "       [-0.1140831 ,  0.12958214, -0.1469076 , ...,  0.05188631,\n",
      "        -0.00336348, -0.11293637],\n",
      "       [-0.09549236,  0.02795191,  0.00085708, ...,  0.05987979,\n",
      "        -0.0712146 ,  0.09914494],\n",
      "       ...,\n",
      "       [ 0.07908665,  0.00378506, -0.04085952, ..., -0.05202832,\n",
      "        -0.01705004,  0.08176069],\n",
      "       [ 0.04903199,  0.08028468, -0.05715871, ...,  0.13089283,\n",
      "        -0.08436675, -0.04846269],\n",
      "       [-0.0181757 , -0.1968197 ,  0.07287313, ..., -0.08488689,\n",
      "        -0.04400666, -0.07827069]], dtype=float32)}, 'c_proj': {'b': array([-0.01742847,  0.07236297, -0.01027654, ...,  0.0499413 ,\n",
      "       -0.11473731,  0.04239384], dtype=float32), 'w': array([[-0.04490146,  0.0749472 ,  0.07872858, ..., -0.04857026,\n",
      "        -0.04225467,  0.04799106],\n",
      "       [ 0.02683727, -0.14289199, -0.16031162, ...,  0.08269325,\n",
      "        -0.0687737 ,  0.12794107],\n",
      "       [-0.13648725, -0.03218469, -0.17341316, ...,  0.2013919 ,\n",
      "        -0.06526611,  0.07542878],\n",
      "       ...,\n",
      "       [-0.05139817, -0.01028677, -0.10155695, ...,  0.068841  ,\n",
      "        -0.05811569,  0.01246699],\n",
      "       [ 0.02448227,  0.0433649 ,  0.00807832, ...,  0.02583949,\n",
      "        -0.08971082, -0.06398955],\n",
      "       [ 0.16457321, -0.04305019, -0.15596485, ..., -0.13034353,\n",
      "         0.16567448,  0.04391181]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.04022595,  0.51165915, -0.05600658, ..., -0.03779331,\n",
      "        0.00125517,  0.02265683], dtype=float32), 'w': array([[ 0.10140707, -0.00203323, -0.16957796, ...,  0.01202587,\n",
      "        -0.15844578,  0.04639478],\n",
      "       [ 0.27253187,  0.06762119,  0.25558463, ..., -0.00397637,\n",
      "        -0.10921513,  0.06941026],\n",
      "       [ 0.09943917,  0.05843368,  0.04665096, ...,  0.01141321,\n",
      "        -0.0558208 ,  0.0905616 ],\n",
      "       ...,\n",
      "       [-0.15619278,  0.10133225,  0.22819708, ...,  0.03836645,\n",
      "        -0.17441927,  0.00073875],\n",
      "       [ 0.11042093,  0.07667574, -0.05864523, ...,  0.07939993,\n",
      "         0.03801425, -0.11055106],\n",
      "       [ 0.13922065, -0.15035245, -0.15638788, ...,  0.02489979,\n",
      "         0.09314387,  0.05808293]], dtype=float32)}, 'c_proj': {'b': array([ 0.0466459 , -0.01222651,  0.09347178, ...,  0.01470459,\n",
      "        0.06330625, -0.08630059], dtype=float32), 'w': array([[-0.11243303,  0.13320707, -0.08052371, ..., -0.1049825 ,\n",
      "        -0.06228834,  0.01670543],\n",
      "       [ 0.04284693, -0.10764023,  0.03596495, ...,  0.02241599,\n",
      "         0.00381335,  0.09559876],\n",
      "       [-0.06565688,  0.11456867,  0.1181298 , ...,  0.02863155,\n",
      "         0.12293768,  0.02529631],\n",
      "       ...,\n",
      "       [-0.01185776, -0.04684037,  0.02267252, ...,  0.04066553,\n",
      "        -0.01650344,  0.0177021 ],\n",
      "       [ 0.01834339, -0.00707008,  0.09810735, ..., -0.05582341,\n",
      "         0.02007052,  0.05819258],\n",
      "       [ 0.00903322,  0.16110739, -0.02884476, ...,  0.09025388,\n",
      "        -0.14400823, -0.02657181]], dtype=float32)}}, 'ln_1': {'b': array([-0.0101229 , -0.01911352, -0.02422438, ..., -0.00595555,\n",
      "       -0.00501561, -0.01111351], dtype=float32), 'g': array([0.5166123 , 0.5289724 , 0.433564  , ..., 0.5410695 , 0.5437392 ,\n",
      "       0.50197375], dtype=float32)}, 'ln_2': {'b': array([-0.01158915, -0.01485129, -0.00899274, ..., -0.00352321,\n",
      "        0.00024325,  0.00191499], dtype=float32), 'g': array([0.4445215 , 0.4547792 , 0.39094064, ..., 0.47390345, 0.45097715,\n",
      "       0.43643716], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.03639687, -0.09084419, -0.14278316, ..., -0.04559734,\n",
      "       -0.01823632, -0.05320954], dtype=float32), 'w': array([[ 0.07639261, -0.0374537 ,  0.00276695, ..., -0.16571757,\n",
      "         0.04906637, -0.01206179],\n",
      "       [ 0.03177181,  0.20180671,  0.02215033, ...,  0.145424  ,\n",
      "        -0.03917758,  0.12008624],\n",
      "       [-0.04034182, -0.11732424,  0.10550163, ..., -0.1468482 ,\n",
      "         0.12137882,  0.07095648],\n",
      "       ...,\n",
      "       [-0.05213721,  0.06186716, -0.07926729, ..., -0.01507327,\n",
      "        -0.10882267, -0.06677605],\n",
      "       [-0.14165771, -0.03979131, -0.11373762, ...,  0.1956119 ,\n",
      "        -0.05296148,  0.27645242],\n",
      "       [ 0.04959413,  0.03791127, -0.07582111, ...,  0.06444451,\n",
      "         0.058317  , -0.25417468]], dtype=float32)}, 'c_proj': {'b': array([-0.04325326,  0.10684969,  0.01393814, ...,  0.02438065,\n",
      "       -0.17686027,  0.0754595 ], dtype=float32), 'w': array([[-0.02023771,  0.00834972,  0.03482429, ...,  0.07789554,\n",
      "        -0.03501734, -0.03425764],\n",
      "       [-0.05649095,  0.09198631, -0.01147388, ...,  0.1152966 ,\n",
      "        -0.05865566, -0.10270214],\n",
      "       [-0.05344157,  0.01571624, -0.2892081 , ..., -0.20969094,\n",
      "         0.16032375,  0.2410994 ],\n",
      "       ...,\n",
      "       [ 0.03106537, -0.05712513,  0.01753084, ...,  0.0436938 ,\n",
      "        -0.16613874, -0.08961776],\n",
      "       [-0.02219971,  0.10256266, -0.09597257, ...,  0.06196532,\n",
      "         0.03946161,  0.03076443],\n",
      "       [ 0.02174706, -0.01680312, -0.11055189, ...,  0.0615005 ,\n",
      "        -0.03860313,  0.03698326]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.05095125, -0.00485645, -0.07791447, ..., -0.00747999,\n",
      "        0.01089101, -0.07108849], dtype=float32), 'w': array([[ 0.03449347,  0.08766188,  0.05056513, ..., -0.02159043,\n",
      "         0.07281715, -0.00815161],\n",
      "       [ 0.17498884,  0.04606451, -0.03591173, ...,  0.09477462,\n",
      "        -0.04373632,  0.00982509],\n",
      "       [ 0.1159959 , -0.0154349 ,  0.0506055 , ...,  0.15201692,\n",
      "        -0.01047992, -0.0440022 ],\n",
      "       ...,\n",
      "       [-0.00290105, -0.22891746,  0.08718318, ..., -0.01736694,\n",
      "         0.05900262,  0.00677815],\n",
      "       [ 0.16519408, -0.21825367, -0.04333205, ..., -0.03897648,\n",
      "         0.06221912, -0.19444786],\n",
      "       [ 0.06452791, -0.13298504,  0.1814253 , ..., -0.06550752,\n",
      "        -0.06651631, -0.15833537]], dtype=float32)}, 'c_proj': {'b': array([ 0.06363611, -0.0531943 ,  0.09121427, ..., -0.05902183,\n",
      "        0.01685853, -0.01700297], dtype=float32), 'w': array([[-0.00120851,  0.05841894,  0.03665338, ..., -0.05641764,\n",
      "         0.02298871, -0.03260996],\n",
      "       [ 0.02085473, -0.03051433,  0.08381379, ...,  0.07627454,\n",
      "        -0.12096136,  0.10976637],\n",
      "       [-0.03820488,  0.00736246,  0.03456527, ...,  0.0459259 ,\n",
      "         0.10021158, -0.10268839],\n",
      "       ...,\n",
      "       [-0.10754611,  0.09311064,  0.16117527, ..., -0.02762235,\n",
      "         0.06250555, -0.08959907],\n",
      "       [ 0.07827459, -0.02684633, -0.0607519 , ...,  0.02830154,\n",
      "         0.05189511,  0.02965256],\n",
      "       [ 0.04631451, -0.06899118, -0.01109499, ...,  0.05172518,\n",
      "        -0.15756862, -0.1589166 ]], dtype=float32)}}, 'ln_1': {'b': array([-0.01396341, -0.01850652, -0.01874934, ..., -0.00841249,\n",
      "       -0.02103843, -0.01944088], dtype=float32), 'g': array([0.5842108 , 0.61109376, 0.50945914, ..., 0.6269696 , 0.62307256,\n",
      "       0.5677702 ], dtype=float32)}, 'ln_2': {'b': array([-0.01219915, -0.01314255,  0.01258716, ...,  0.02822418,\n",
      "       -0.01892113,  0.00793825], dtype=float32), 'g': array([0.44388837, 0.46239683, 0.42101648, ..., 0.49301508, 0.47118002,\n",
      "       0.45428747], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.08253795, -0.0880428 , -0.12790376, ..., -0.1311132 ,\n",
      "       -0.0347688 , -0.0974528 ], dtype=float32), 'w': array([[ 0.01534977,  0.04869705,  0.06231074, ...,  0.1118893 ,\n",
      "        -0.1177581 , -0.01934267],\n",
      "       [ 0.01433307, -0.22270015,  0.00769735, ..., -0.02360983,\n",
      "        -0.19013774, -0.18612517],\n",
      "       [ 0.02243433,  0.02619429,  0.06931313, ...,  0.06973536,\n",
      "         0.20636469,  0.04266931],\n",
      "       ...,\n",
      "       [ 0.03083027,  0.15672958,  0.11747036, ...,  0.08911107,\n",
      "        -0.16180345,  0.014829  ],\n",
      "       [ 0.10298618,  0.02448061, -0.06246537, ...,  0.27892086,\n",
      "         0.02993518,  0.14866751],\n",
      "       [-0.02579993, -0.00034626, -0.01673562, ..., -0.07156133,\n",
      "        -0.04815228,  0.0099968 ]], dtype=float32)}, 'c_proj': {'b': array([-0.03748678,  0.13934971, -0.00039017, ...,  0.02499976,\n",
      "       -0.1340738 ,  0.03240503], dtype=float32), 'w': array([[ 0.18311995, -0.0465935 , -0.05843037, ...,  0.09092334,\n",
      "        -0.03896906, -0.19165652],\n",
      "       [-0.0717136 , -0.06519331, -0.08039835, ...,  0.02807136,\n",
      "        -0.02184736,  0.12634753],\n",
      "       [-0.04711166, -0.05274931,  0.0871657 , ...,  0.15252613,\n",
      "        -0.12473649,  0.01670096],\n",
      "       ...,\n",
      "       [-0.00554847, -0.01132425,  0.09501334, ..., -0.07716641,\n",
      "        -0.10521417, -0.0258977 ],\n",
      "       [ 0.03006046,  0.20138638, -0.12358908, ...,  0.08186108,\n",
      "         0.06608637,  0.16198468],\n",
      "       [ 0.122522  , -0.06278852,  0.01680938, ...,  0.00674525,\n",
      "        -0.0044419 , -0.2607618 ]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([-0.1354624 ,  0.0418997 ,  0.02354493, ..., -0.00190838,\n",
      "        0.00650196, -0.01348935], dtype=float32), 'w': array([[-0.12363021, -0.13627449,  0.09758358, ..., -0.02912661,\n",
      "         0.05033091,  0.00781044],\n",
      "       [-0.04843485,  0.08859425,  0.09233361, ..., -0.02149561,\n",
      "         0.03077745,  0.04241043],\n",
      "       [-0.08984605,  0.15635519, -0.05606068, ...,  0.00859896,\n",
      "         0.08000468,  0.03090839],\n",
      "       ...,\n",
      "       [ 0.05093586,  0.1726897 , -0.19369082, ...,  0.00364324,\n",
      "         0.01219266, -0.07340188],\n",
      "       [-0.07472827,  0.01855261,  0.14973655, ..., -0.08351213,\n",
      "        -0.11823162,  0.04604954],\n",
      "       [ 0.17001957, -0.25993738, -0.00989356, ..., -0.07474876,\n",
      "         0.02785611,  0.17309651]], dtype=float32)}, 'c_proj': {'b': array([-0.04797576, -0.01365153,  0.11818668, ...,  0.03466704,\n",
      "       -0.0078424 , -0.11087439], dtype=float32), 'w': array([[ 0.05995582, -0.0899891 , -0.06879179, ..., -0.06251003,\n",
      "        -0.0302185 ,  0.10326088],\n",
      "       [ 0.00835764, -0.03633938,  0.01945864, ..., -0.00262669,\n",
      "         0.1134174 , -0.15341091],\n",
      "       [ 0.14802067, -0.02734565,  0.00093574, ..., -0.04282654,\n",
      "         0.00353814, -0.16894683],\n",
      "       ...,\n",
      "       [ 0.03069513, -0.06289984, -0.12903748, ..., -0.01510816,\n",
      "        -0.09156534, -0.03725329],\n",
      "       [-0.01363651,  0.13686654, -0.02970372, ..., -0.07154995,\n",
      "        -0.10832419, -0.01119577],\n",
      "       [-0.06122774, -0.02226327,  0.03566168, ..., -0.01516137,\n",
      "        -0.04281731,  0.21008764]], dtype=float32)}}, 'ln_1': {'b': array([-0.01237538, -0.01468193, -0.02629324, ..., -0.0091929 ,\n",
      "       -0.01896555, -0.01464986], dtype=float32), 'g': array([0.5280748 , 0.5503996 , 0.46424702, ..., 0.5636852 , 0.55225897,\n",
      "       0.5061658 ], dtype=float32)}, 'ln_2': {'b': array([-0.01238029,  0.01012945,  0.01849044, ...,  0.00711527,\n",
      "        0.0044968 ,  0.01210103], dtype=float32), 'g': array([0.4278254 , 0.44413593, 0.38493305, ..., 0.4579046 , 0.42884555,\n",
      "       0.41499975], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.0275776 , -0.05019501, -0.11638534, ..., -0.02694008,\n",
      "       -0.03547709, -0.07289882], dtype=float32), 'w': array([[-0.08701326,  0.05707554,  0.031307  , ...,  0.04047457,\n",
      "        -0.04705023, -0.17659579],\n",
      "       [ 0.01857722,  0.04728734,  0.15128224, ..., -0.10045492,\n",
      "        -0.01144844, -0.10464256],\n",
      "       [-0.04394295, -0.05519319,  0.09703398, ..., -0.01897365,\n",
      "        -0.05520601, -0.02750799],\n",
      "       ...,\n",
      "       [-0.03446789, -0.03147721, -0.05663263, ...,  0.12446519,\n",
      "        -0.04174638,  0.1419588 ],\n",
      "       [-0.19190355,  0.21835442, -0.01261057, ...,  0.05824023,\n",
      "         0.04237473,  0.00898121],\n",
      "       [ 0.02767436,  0.07142463,  0.11044858, ..., -0.02257117,\n",
      "         0.02376967, -0.05900574]], dtype=float32)}, 'c_proj': {'b': array([-0.04672756,  0.09196431,  0.00924776, ...,  0.13235883,\n",
      "       -0.07482127,  0.06023325], dtype=float32), 'w': array([[-0.03543363,  0.08667645, -0.15138552, ...,  0.04196794,\n",
      "        -0.00902413, -0.01042726],\n",
      "       [-0.08911687, -0.01338406,  0.0062829 , ..., -0.02659196,\n",
      "        -0.18400854, -0.03707933],\n",
      "       [ 0.07102416,  0.1434736 , -0.06857755, ...,  0.00562529,\n",
      "        -0.07816803,  0.01286837],\n",
      "       ...,\n",
      "       [-0.02990059,  0.15268858, -0.08397206, ..., -0.1063439 ,\n",
      "         0.04297401,  0.11613987],\n",
      "       [ 0.01576848,  0.13599089, -0.0151657 , ..., -0.02424477,\n",
      "        -0.09429391, -0.0885597 ],\n",
      "       [ 0.06412511, -0.12229628, -0.04183847, ..., -0.11602743,\n",
      "         0.00062971,  0.12797076]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.00207662,  0.06996937, -0.09350834, ..., -0.00480197,\n",
      "        0.00844937, -0.01811131], dtype=float32), 'w': array([[ 0.1316695 , -0.08124676,  0.05248202, ...,  0.01234494,\n",
      "        -0.05147194, -0.37435094],\n",
      "       [-0.07659536,  0.12777714,  0.00498912, ..., -0.18940294,\n",
      "        -0.04009742, -0.02308281],\n",
      "       [-0.05960069, -0.0663392 , -0.03681505, ..., -0.14217661,\n",
      "        -0.12741114,  0.03871194],\n",
      "       ...,\n",
      "       [-0.03126198,  0.06593084,  0.00895726, ...,  0.14008653,\n",
      "         0.06142749,  0.19622347],\n",
      "       [ 0.03085037, -0.08195151,  0.29297882, ...,  0.22078122,\n",
      "         0.14135252, -0.06039545],\n",
      "       [-0.08398528,  0.10357116,  0.17960697, ..., -0.17081498,\n",
      "        -0.07067526, -0.03389398]], dtype=float32)}, 'c_proj': {'b': array([-0.0242236 ,  0.01945307,  0.11290009, ..., -0.13858695,\n",
      "        0.06138032, -0.07750478], dtype=float32), 'w': array([[ 0.02352235, -0.13204788, -0.03934835, ...,  0.00195185,\n",
      "        -0.02758503,  0.07324653],\n",
      "       [-0.02043696, -0.06118485,  0.11025316, ...,  0.10279122,\n",
      "        -0.11043188, -0.256222  ],\n",
      "       [-0.09482212,  0.05379088, -0.0381435 , ...,  0.0580909 ,\n",
      "         0.02714494, -0.08494523],\n",
      "       ...,\n",
      "       [ 0.03204236,  0.18150286,  0.14958872, ..., -0.04515747,\n",
      "        -0.01098831,  0.07535794],\n",
      "       [ 0.06974052, -0.02066257,  0.04228236, ...,  0.02271638,\n",
      "        -0.04161813, -0.24351844],\n",
      "       [ 0.01818299, -0.1094056 ,  0.08250592, ...,  0.02089663,\n",
      "        -0.03127278, -0.00177523]], dtype=float32)}}, 'ln_1': {'b': array([-0.01226812, -0.01799936, -0.02206119, ..., -0.00551726,\n",
      "       -0.01190589, -0.01111404], dtype=float32), 'g': array([0.5292939 , 0.5401268 , 0.45613024, ..., 0.5527656 , 0.5498431 ,\n",
      "       0.521368  ], dtype=float32)}, 'ln_2': {'b': array([-0.01599181,  0.00802902,  0.02397109, ...,  0.01733532,\n",
      "       -0.00252815,  0.0058645 ], dtype=float32), 'g': array([0.39905652, 0.40442204, 0.37747106, ..., 0.42150995, 0.39869136,\n",
      "       0.3996613 ], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.03734168, -0.06340174, -0.12182627, ..., -0.1229829 ,\n",
      "       -0.06102826, -0.10399037], dtype=float32), 'w': array([[ 0.13637061, -0.07805067, -0.06200496, ...,  0.10085025,\n",
      "         0.15596016,  0.1627695 ],\n",
      "       [-0.02231426,  0.07801808, -0.06101882, ...,  0.00272531,\n",
      "        -0.04369408,  0.01837822],\n",
      "       [-0.03121326, -0.04566402,  0.11328719, ..., -0.11950437,\n",
      "        -0.01343047, -0.00604142],\n",
      "       ...,\n",
      "       [ 0.06622064, -0.18926145,  0.01822262, ...,  0.13692614,\n",
      "         0.03856712, -0.04897068],\n",
      "       [-0.16078603, -0.06584278,  0.03162451, ...,  0.14920829,\n",
      "        -0.02140588, -0.01404411],\n",
      "       [ 0.04216977, -0.0784701 ,  0.10891494, ..., -0.02054086,\n",
      "         0.08833432, -0.11156806]], dtype=float32)}, 'c_proj': {'b': array([-3.2903686e-02,  1.2827903e-01, -3.0994045e-02, ...,\n",
      "        1.0487571e-01,  1.0559407e-04,  4.6887868e-03], dtype=float32), 'w': array([[-5.68167120e-02,  4.32960019e-02,  5.47429919e-02, ...,\n",
      "         1.22212851e-02,  8.93506110e-02, -1.83185767e-02],\n",
      "       [-1.65492282e-04,  4.16845977e-02,  1.05711907e-01, ...,\n",
      "         5.28281480e-02,  2.80843806e-02,  2.51101460e-02],\n",
      "       [ 2.69073620e-03,  1.33205190e-01,  1.84155703e-01, ...,\n",
      "        -9.53566432e-02, -1.12224504e-01,  9.47936671e-04],\n",
      "       ...,\n",
      "       [-5.57433069e-03,  1.14824913e-01, -7.53199607e-02, ...,\n",
      "         1.90833196e-01,  1.41680330e-01, -9.84518416e-03],\n",
      "       [ 3.03963087e-02, -9.89410132e-02,  4.88580950e-02, ...,\n",
      "         8.72329399e-02,  1.37120783e-02, -1.93130657e-01],\n",
      "       [-5.37288077e-02, -3.91434245e-02,  3.05406135e-02, ...,\n",
      "        -1.48396090e-01,  7.09477589e-02, -5.90432342e-03]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([-0.2990934 , -0.08017605,  0.09833018, ...,  0.00885028,\n",
      "        0.00994626, -0.01176196], dtype=float32), 'w': array([[-0.13709071,  0.11552044, -0.14939979, ...,  0.1190522 ,\n",
      "        -0.1444422 ,  0.01751267],\n",
      "       [ 0.24376313,  0.142341  , -0.03106231, ..., -0.15231128,\n",
      "        -0.01946684, -0.03584665],\n",
      "       [ 0.02378047,  0.17814866,  0.02040131, ..., -0.12235978,\n",
      "        -0.15158401, -0.04677641],\n",
      "       ...,\n",
      "       [-0.14016736, -0.02380683,  0.11590169, ...,  0.03193648,\n",
      "         0.07721192,  0.14581923],\n",
      "       [-0.0360091 ,  0.01978   ,  0.04151521, ..., -0.03327231,\n",
      "         0.15005828,  0.19635396],\n",
      "       [ 0.1710497 ,  0.1439749 ,  0.16231608, ..., -0.04508288,\n",
      "         0.08562271,  0.05843224]], dtype=float32)}, 'c_proj': {'b': array([-0.01524277,  0.06829756,  0.14678021, ..., -0.10335743,\n",
      "        0.01192935, -0.0813847 ], dtype=float32), 'w': array([[ 0.03998672,  0.02288314,  0.04467765, ...,  0.15791243,\n",
      "         0.01398284,  0.09202093],\n",
      "       [-0.1733697 , -0.00082127, -0.06869852, ..., -0.10763464,\n",
      "        -0.09977479,  0.04069183],\n",
      "       [ 0.06919339, -0.10802989, -0.04080511, ..., -0.0397971 ,\n",
      "         0.00635311,  0.12251981],\n",
      "       ...,\n",
      "       [ 0.00761746, -0.00621854,  0.07251419, ..., -0.01972986,\n",
      "         0.04390967, -0.0537572 ],\n",
      "       [-0.19378532, -0.09209805,  0.06174673, ..., -0.08871199,\n",
      "        -0.00064398, -0.10284262],\n",
      "       [-0.00391941,  0.1022775 ,  0.00784062, ..., -0.10623836,\n",
      "         0.00341515, -0.14202479]], dtype=float32)}}, 'ln_1': {'b': array([-0.01472649, -0.01346111, -0.01980051, ..., -0.01170638,\n",
      "       -0.02049302, -0.01343835], dtype=float32), 'g': array([0.5143176 , 0.5284533 , 0.48553085, ..., 0.5488285 , 0.528474  ,\n",
      "       0.48516044], dtype=float32)}, 'ln_2': {'b': array([-0.02209441,  0.00738148,  0.01624054, ...,  0.02855084,\n",
      "        0.02446283,  0.00998965], dtype=float32), 'g': array([0.39277315, 0.39148042, 0.3681007 , ..., 0.41689864, 0.39682725,\n",
      "       0.38979864], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.02408551, -0.04793927, -0.08869565, ..., -0.01040753,\n",
      "       -0.09310789, -0.02126161], dtype=float32), 'w': array([[ 0.01609529,  0.06635877,  0.05082177, ...,  0.15489839,\n",
      "        -0.02441306, -0.00850343],\n",
      "       [-0.02187666,  0.05790325, -0.14947887, ...,  0.00100071,\n",
      "        -0.03755965, -0.17103127],\n",
      "       [ 0.04718129,  0.00844055, -0.01896098, ..., -0.08871256,\n",
      "        -0.0678008 , -0.05980784],\n",
      "       ...,\n",
      "       [-0.08310063, -0.00056453, -0.17067045, ..., -0.01592998,\n",
      "        -0.08644299,  0.1730946 ],\n",
      "       [-0.03055947, -0.05983824, -0.1074001 , ..., -0.05526481,\n",
      "        -0.06833035, -0.13794626],\n",
      "       [ 0.06670775, -0.03086714, -0.10681507, ...,  0.01710564,\n",
      "        -0.00512435, -0.00513136]], dtype=float32)}, 'c_proj': {'b': array([-0.04873806,  0.121244  ,  0.00591369, ...,  0.19714592,\n",
      "       -0.00374846, -0.0109442 ], dtype=float32), 'w': array([[ 0.07996043,  0.03000606,  0.00651545, ..., -0.00693646,\n",
      "         0.08725367, -0.07676712],\n",
      "       [ 0.09263538,  0.01084152, -0.09472511, ...,  0.01058347,\n",
      "         0.04304332,  0.09686194],\n",
      "       [-0.11844002,  0.03145397, -0.03800533, ..., -0.08056328,\n",
      "        -0.05498882, -0.05183638],\n",
      "       ...,\n",
      "       [-0.12189942, -0.13026984,  0.11846133, ..., -0.02050882,\n",
      "         0.17089123,  0.0629982 ],\n",
      "       [-0.0941877 , -0.09799743, -0.07769869, ...,  0.10618875,\n",
      "         0.01479109, -0.19439667],\n",
      "       [ 0.10589147,  0.21204622,  0.01196402, ..., -0.10940258,\n",
      "         0.06893717,  0.11216463]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.06900948,  0.19519688, -0.11626519, ...,  0.00144198,\n",
      "       -0.00606249,  0.0119562 ], dtype=float32), 'w': array([[ 0.05367935,  0.030801  , -0.15576059, ...,  0.13202606,\n",
      "        -0.19977638, -0.02236515],\n",
      "       [ 0.11705018, -0.11152203, -0.03659735, ..., -0.07777307,\n",
      "         0.07669204,  0.06141007],\n",
      "       [ 0.03164608,  0.05748874,  0.12742141, ..., -0.13953753,\n",
      "         0.07254022, -0.02990407],\n",
      "       ...,\n",
      "       [ 0.10111625,  0.02022938,  0.10095146, ..., -0.04425626,\n",
      "         0.00048325, -0.01476608],\n",
      "       [-0.04842154,  0.13029791, -0.0385133 , ..., -0.01986168,\n",
      "        -0.0097623 ,  0.14964342],\n",
      "       [-0.10237513,  0.25104883,  0.01296674, ...,  0.03392014,\n",
      "        -0.18218888, -0.10910834]], dtype=float32)}, 'c_proj': {'b': array([ 0.00764433,  0.02739935,  0.05441312, ..., -0.11082279,\n",
      "       -0.04988308, -0.09011566], dtype=float32), 'w': array([[ 0.05770011, -0.0050352 , -0.10018685, ..., -0.01190299,\n",
      "         0.00716   ,  0.173317  ],\n",
      "       [ 0.082948  , -0.0387563 ,  0.10521556, ...,  0.07116735,\n",
      "         0.05581943, -0.05412062],\n",
      "       [ 0.04942409, -0.20489582, -0.02263368, ...,  0.04414763,\n",
      "        -0.00796562, -0.13573986],\n",
      "       ...,\n",
      "       [ 0.17496109,  0.03111482,  0.02942109, ...,  0.04907481,\n",
      "        -0.02264287,  0.01399233],\n",
      "       [-0.03406924,  0.06084087, -0.0275854 , ..., -0.0234191 ,\n",
      "        -0.15234832, -0.06982016],\n",
      "       [ 0.11403936, -0.12051062, -0.08605036, ...,  0.01962123,\n",
      "        -0.07061816, -0.01760058]], dtype=float32)}}, 'ln_1': {'b': array([-0.01419128, -0.00945623, -0.01815837, ..., -0.00320187,\n",
      "       -0.01170958, -0.01081261], dtype=float32), 'g': array([0.47551432, 0.4686992 , 0.41000354, ..., 0.48096642, 0.465134  ,\n",
      "       0.4519371 ], dtype=float32)}, 'ln_2': {'b': array([-0.01494846,  0.03243025,  0.03044018, ...,  0.01981367,\n",
      "        0.02232701,  0.01131087], dtype=float32), 'g': array([0.37084183, 0.3846523 , 0.35873923, ..., 0.40060896, 0.38455358,\n",
      "       0.3681607 ], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.09582384,  0.01910218, -0.13123952, ..., -0.07434634,\n",
      "       -0.09655035, -0.00828366], dtype=float32), 'w': array([[ 0.00071023, -0.13813697, -0.10365443, ..., -0.02093379,\n",
      "         0.07228119, -0.02451829],\n",
      "       [ 0.1368567 ,  0.02942011, -0.14210886, ..., -0.08231954,\n",
      "        -0.00553274,  0.11791911],\n",
      "       [ 0.09012652,  0.02079448, -0.05166197, ..., -0.08342039,\n",
      "        -0.00775823, -0.02536947],\n",
      "       ...,\n",
      "       [ 0.04657944, -0.01021435,  0.18068962, ..., -0.04947487,\n",
      "         0.02577602,  0.04778008],\n",
      "       [-0.08239971,  0.07262333,  0.17712541, ...,  0.2594869 ,\n",
      "        -0.13011345, -0.08370253],\n",
      "       [-0.05271006,  0.03130422,  0.11140419, ..., -0.03440659,\n",
      "         0.10570054,  0.06618873]], dtype=float32)}, 'c_proj': {'b': array([-0.0741833 ,  0.07509642, -0.00170132, ...,  0.18532644,\n",
      "       -0.02640553,  0.05534466], dtype=float32), 'w': array([[ 0.01702274, -0.02055848, -0.12078013, ...,  0.15270063,\n",
      "        -0.06036318, -0.27396178],\n",
      "       [ 0.09218325,  0.07347502, -0.04914167, ...,  0.1234749 ,\n",
      "        -0.20835917, -0.07430499],\n",
      "       [-0.18810725, -0.05201005,  0.09285676, ..., -0.09206408,\n",
      "        -0.05273094,  0.06090757],\n",
      "       ...,\n",
      "       [-0.06760851, -0.00629009,  0.1164661 , ...,  0.04120728,\n",
      "        -0.09152552, -0.07396183],\n",
      "       [-0.0472031 , -0.02558554,  0.14134394, ...,  0.00839115,\n",
      "        -0.01231962,  0.05540232],\n",
      "       [-0.03960348, -0.07331388, -0.04609785, ...,  0.01383901,\n",
      "        -0.01350777, -0.02616984]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.00359859, -0.17067875, -0.04780267, ...,  0.03029569,\n",
      "       -0.00836208,  0.00452122], dtype=float32), 'w': array([[-0.3030608 ,  0.33427367, -0.17452556, ..., -0.1417    ,\n",
      "        -0.05005872,  0.01853579],\n",
      "       [ 0.11326478,  0.05315757,  0.0544748 , ...,  0.04277442,\n",
      "         0.08898192, -0.227889  ],\n",
      "       [-0.08404769,  0.08436298,  0.06400804, ...,  0.01702997,\n",
      "         0.07853337,  0.00216911],\n",
      "       ...,\n",
      "       [-0.17328243, -0.0031885 ,  0.0801781 , ...,  0.03676537,\n",
      "         0.03433562, -0.02772987],\n",
      "       [-0.03367947,  0.00898556, -0.08080361, ...,  0.266364  ,\n",
      "         0.05772821,  0.06304033],\n",
      "       [ 0.09529758, -0.02906961,  0.1907185 , ...,  0.0131724 ,\n",
      "         0.05025019, -0.12863937]], dtype=float32)}, 'c_proj': {'b': array([-0.03361324,  0.05595059,  0.1034579 , ..., -0.15941729,\n",
      "       -0.0416232 , -0.04466496], dtype=float32), 'w': array([[ 0.04787118,  0.07789317,  0.1151478 , ...,  0.17652638,\n",
      "         0.1091848 , -0.05777263],\n",
      "       [-0.05493242, -0.01927881,  0.11033573, ...,  0.10319714,\n",
      "        -0.12913719,  0.10016558],\n",
      "       [-0.00128488,  0.18952131, -0.01509361, ...,  0.1809165 ,\n",
      "         0.03039605, -0.00677752],\n",
      "       ...,\n",
      "       [ 0.01138659, -0.14532755,  0.02737331, ..., -0.07984909,\n",
      "         0.05891323, -0.15027267],\n",
      "       [ 0.01365042, -0.10925984, -0.11496185, ...,  0.13725065,\n",
      "        -0.0312861 , -0.05078688],\n",
      "       [-0.03866662,  0.02045643, -0.03032186, ..., -0.01788754,\n",
      "         0.04980507,  0.10411279]], dtype=float32)}}, 'ln_1': {'b': array([-0.01486736, -0.01313601, -0.02060902, ..., -0.00484479,\n",
      "       -0.01699729, -0.01472523], dtype=float32), 'g': array([0.48142305, 0.4789471 , 0.44662833, ..., 0.50283825, 0.46980837,\n",
      "       0.45307085], dtype=float32)}, 'ln_2': {'b': array([-0.02376949,  0.04175227,  0.03579893, ...,  0.01749526,\n",
      "        0.022546  ,  0.04146545], dtype=float32), 'g': array([0.3697731 , 0.38473538, 0.350622  , ..., 0.38454786, 0.36616406,\n",
      "       0.36948663], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.03894724, -0.05693998, -0.00925147, ..., -0.06293894,\n",
      "       -0.12603027, -0.0281732 ], dtype=float32), 'w': array([[-0.11854424,  0.0036218 ,  0.01953066, ..., -0.08271185,\n",
      "         0.17617713,  0.05291957],\n",
      "       [-0.04785018,  0.18148011, -0.02608977, ...,  0.04351024,\n",
      "         0.0458976 ,  0.03338904],\n",
      "       [ 0.04954385,  0.00078962,  0.06445678, ..., -0.05535509,\n",
      "        -0.21595688, -0.14490095],\n",
      "       ...,\n",
      "       [-0.03899448,  0.01892202,  0.06226209, ...,  0.02375266,\n",
      "         0.00220112, -0.11287535],\n",
      "       [ 0.11553169,  0.04771908,  0.06947061, ..., -0.04196221,\n",
      "        -0.18766381, -0.03219455],\n",
      "       [-0.02548358, -0.01933699, -0.13173272, ...,  0.04258642,\n",
      "        -0.12425821, -0.20462023]], dtype=float32)}, 'c_proj': {'b': array([-0.08983375,  0.08365236, -0.01851371, ...,  0.18464658,\n",
      "        0.00465309,  0.00947912], dtype=float32), 'w': array([[ 0.12208675,  0.06377908, -0.00407653, ..., -0.14674015,\n",
      "        -0.1680806 ,  0.0226875 ],\n",
      "       [-0.15666798,  0.04367556, -0.03876797, ...,  0.14073104,\n",
      "        -0.18381643,  0.13956188],\n",
      "       [ 0.02842963, -0.2235217 ,  0.01437085, ..., -0.01736819,\n",
      "         0.01162196,  0.00662135],\n",
      "       ...,\n",
      "       [-0.06892432, -0.00925899,  0.00206619, ...,  0.04280716,\n",
      "        -0.09053636,  0.12436976],\n",
      "       [ 0.260314  , -0.11070157,  0.08513511, ..., -0.12234132,\n",
      "        -0.11376646,  0.11109519],\n",
      "       [-0.15592043,  0.14603256,  0.03012961, ...,  0.04137047,\n",
      "        -0.03669288, -0.09195555]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.02506443,  0.33418202,  0.09421922, ...,  0.0146743 ,\n",
      "       -0.03030528,  0.01263069], dtype=float32), 'w': array([[ 0.0643339 ,  0.02895563, -0.02098675, ..., -0.14432363,\n",
      "        -0.04803669,  0.1419652 ],\n",
      "       [ 0.01155349, -0.02400357,  0.01999211, ..., -0.00594776,\n",
      "        -0.0395537 ,  0.08388364],\n",
      "       [ 0.12171061,  0.08744158, -0.17538366, ..., -0.0053238 ,\n",
      "        -0.01813175,  0.00479226],\n",
      "       ...,\n",
      "       [-0.03251271,  0.09133349,  0.05683754, ..., -0.13402553,\n",
      "        -0.04082765, -0.05719557],\n",
      "       [-0.02582245,  0.01884269, -0.04083453, ...,  0.02195463,\n",
      "         0.09823196, -0.09090456],\n",
      "       [-0.21161444, -0.0757624 ,  0.10342088, ..., -0.01113813,\n",
      "         0.16871485, -0.04314441]], dtype=float32)}, 'c_proj': {'b': array([-0.04338836,  0.00143074,  0.01683048, ..., -0.20376475,\n",
      "       -0.01132339,  0.03634313], dtype=float32), 'w': array([[-0.06642701, -0.07055847,  0.01589044, ..., -0.16204427,\n",
      "        -0.2089322 ,  0.03404523],\n",
      "       [ 0.00262286, -0.10901439,  0.0393969 , ...,  0.21736993,\n",
      "        -0.05358923, -0.12106673],\n",
      "       [-0.01711868,  0.05729282,  0.01380302, ...,  0.08559672,\n",
      "        -0.17554812, -0.02328073],\n",
      "       ...,\n",
      "       [ 0.0134021 ,  0.07524888,  0.08485077, ..., -0.15955791,\n",
      "         0.20654574, -0.14095189],\n",
      "       [-0.04486423, -0.00942564,  0.03161768, ...,  0.03949096,\n",
      "         0.11282354,  0.13912822],\n",
      "       [ 0.18948162, -0.02118225, -0.0613469 , ...,  0.02118016,\n",
      "        -0.00850357, -0.08396231]], dtype=float32)}}, 'ln_1': {'b': array([-0.01933117, -0.00995537, -0.02227052, ...,  0.00261446,\n",
      "       -0.01290468, -0.01205508], dtype=float32), 'g': array([0.4716302 , 0.45019466, 0.4344634 , ..., 0.47423694, 0.45794424,\n",
      "       0.436528  ], dtype=float32)}, 'ln_2': {'b': array([-0.00972138,  0.03786955,  0.03033811, ...,  0.02822433,\n",
      "        0.0418867 ,  0.01105697], dtype=float32), 'g': array([0.3639319 , 0.36723745, 0.35064182, ..., 0.37793425, 0.373983  ,\n",
      "       0.34912348], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.13475108, -0.04261713, -0.00184055, ..., -0.07810686,\n",
      "       -0.02284667, -0.11002402], dtype=float32), 'w': array([[ 0.22546118,  0.17963724, -0.02795175, ...,  0.07904702,\n",
      "        -0.03475867, -0.13712616],\n",
      "       [ 0.02298845,  0.06220395,  0.03874818, ..., -0.09851298,\n",
      "         0.06563723,  0.06641442],\n",
      "       [ 0.02749809, -0.02359328,  0.04834355, ...,  0.00187156,\n",
      "         0.02447893, -0.10541802],\n",
      "       ...,\n",
      "       [-0.16975977,  0.07582396, -0.00512635, ...,  0.10415884,\n",
      "         0.1049423 , -0.07209011],\n",
      "       [ 0.05351676, -0.0057189 ,  0.099866  , ..., -0.0794796 ,\n",
      "        -0.1360564 , -0.08510878],\n",
      "       [-0.02801062, -0.32933956, -0.02102027, ..., -0.13465278,\n",
      "        -0.05823308, -0.08858904]], dtype=float32)}, 'c_proj': {'b': array([-0.13496397,  0.10622712, -0.04135424, ...,  0.23365083,\n",
      "        0.09235721, -0.01523521], dtype=float32), 'w': array([[ 0.0132722 ,  0.07388341, -0.03765192, ...,  0.0126098 ,\n",
      "        -0.0561702 , -0.0049016 ],\n",
      "       [-0.18049686,  0.04915713,  0.13032831, ...,  0.0247517 ,\n",
      "        -0.07394093,  0.3123437 ],\n",
      "       [-0.00871887, -0.1263396 , -0.05137816, ...,  0.11068218,\n",
      "        -0.11576605, -0.04883129],\n",
      "       ...,\n",
      "       [-0.09967119, -0.04886343, -0.05256491, ...,  0.03091028,\n",
      "         0.06453006,  0.08288773],\n",
      "       [ 0.10564817, -0.12351269, -0.10004736, ..., -0.18465476,\n",
      "         0.03170139, -0.03325756],\n",
      "       [ 0.03985389,  0.01740322,  0.0262662 , ..., -0.02412527,\n",
      "         0.16232885,  0.09942707]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.03354933,  0.13351843, -0.5192653 , ...,  0.02325051,\n",
      "       -0.00124785, -0.01821352], dtype=float32), 'w': array([[ 0.02525234, -0.08511756,  0.01403903, ...,  0.07464317,\n",
      "        -0.15016194,  0.16268176],\n",
      "       [ 0.02326755,  0.08028553,  0.02873627, ...,  0.058947  ,\n",
      "        -0.07239942,  0.13060637],\n",
      "       [-0.1271568 , -0.01873662, -0.00578523, ..., -0.07529852,\n",
      "        -0.01941441,  0.07983959],\n",
      "       ...,\n",
      "       [ 0.0460287 ,  0.06930218, -0.07145317, ..., -0.116221  ,\n",
      "         0.05647022, -0.08122559],\n",
      "       [-0.20072338, -0.06150251,  0.02942467, ..., -0.01594873,\n",
      "         0.00281423, -0.16030498],\n",
      "       [-0.04601807,  0.24496742, -0.02119318, ...,  0.07893573,\n",
      "         0.01002988, -0.04699354]], dtype=float32)}, 'c_proj': {'b': array([ 0.05403651, -0.00173271,  0.07441892, ..., -0.16854614,\n",
      "       -0.09188499,  0.06140356], dtype=float32), 'w': array([[ 0.11502231, -0.00241281,  0.06290093, ...,  0.23239811,\n",
      "        -0.02507897,  0.30189463],\n",
      "       [ 0.23493837,  0.0183077 , -0.17179643, ..., -0.03434347,\n",
      "         0.12047882,  0.00130278],\n",
      "       [ 0.10551368,  0.09379503,  0.03715999, ...,  0.14837499,\n",
      "         0.03306535, -0.03532177],\n",
      "       ...,\n",
      "       [-0.02290973,  0.05415074,  0.15983298, ...,  0.10024003,\n",
      "         0.0915176 , -0.09096199],\n",
      "       [ 0.1244063 ,  0.06924107, -0.09201283, ...,  0.00315637,\n",
      "        -0.1010974 ,  0.09979106],\n",
      "       [-0.06293581,  0.18522766, -0.0548256 , ...,  0.05711747,\n",
      "        -0.11739855, -0.03154767]], dtype=float32)}}, 'ln_1': {'b': array([-0.02164525, -0.00880696, -0.01387956, ..., -0.003968  ,\n",
      "       -0.01015402, -0.00718417], dtype=float32), 'g': array([0.46075752, 0.45609507, 0.43420267, ..., 0.47551492, 0.4540645 ,\n",
      "       0.43698937], dtype=float32)}, 'ln_2': {'b': array([-0.00195047,  0.03420556,  0.04375068, ...,  0.00486074,\n",
      "        0.03668008,  0.02999917], dtype=float32), 'g': array([0.37981677, 0.37355578, 0.3475299 , ..., 0.37949014, 0.37967002,\n",
      "       0.36029318], dtype=float32)}, 'mlp': {'c_fc': {'b': array([ 0.04711109, -0.02109359, -0.09062633, ..., -0.09890774,\n",
      "       -0.10821623, -0.01641595], dtype=float32), 'w': array([[-0.05169072, -0.00534802, -0.0355036 , ...,  0.06957651,\n",
      "        -0.16926487, -0.04120998],\n",
      "       [-0.13456467,  0.25637522,  0.12798487, ..., -0.07162691,\n",
      "        -0.07851356, -0.05189725],\n",
      "       [-0.02226736,  0.01267031,  0.12465417, ...,  0.0114302 ,\n",
      "         0.12105128, -0.07339738],\n",
      "       ...,\n",
      "       [-0.17917159,  0.1255893 ,  0.13273804, ..., -0.13084789,\n",
      "        -0.06849201,  0.0728188 ],\n",
      "       [-0.0684832 , -0.03609666, -0.00092459, ..., -0.10316207,\n",
      "        -0.04804049, -0.1904419 ],\n",
      "       [ 0.06786961,  0.11828955, -0.0287997 , ..., -0.11596098,\n",
      "        -0.02034273, -0.05320247]], dtype=float32)}, 'c_proj': {'b': array([-0.05373675,  0.03075241, -0.05606655, ...,  0.2070382 ,\n",
      "       -0.05662014, -0.04666325], dtype=float32), 'w': array([[ 0.04717903,  0.11569493,  0.20174685, ...,  0.00090421,\n",
      "         0.0968824 , -0.00986315],\n",
      "       [-0.10609563, -0.18213181, -0.03240505, ..., -0.17543522,\n",
      "         0.18885286,  0.05970429],\n",
      "       [-0.06225304, -0.27589148, -0.00946963, ..., -0.16836989,\n",
      "         0.06305924, -0.08009814],\n",
      "       ...,\n",
      "       [ 0.18284598, -0.02762928,  0.0078424 , ..., -0.0577943 ,\n",
      "        -0.02726978,  0.07358044],\n",
      "       [-0.12317393, -0.09383965,  0.00360963, ..., -0.03668685,\n",
      "        -0.05603227,  0.00269853],\n",
      "       [-0.02934011, -0.10928287,  0.11116596, ..., -0.17704831,\n",
      "         0.09288245, -0.19594775]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.08280148,  0.05493094,  0.04152665, ...,  0.00263492,\n",
      "       -0.00644342,  0.01447246], dtype=float32), 'w': array([[-0.00356147, -0.08864684,  0.20930314, ..., -0.09188121,\n",
      "        -0.12290733,  0.16249587],\n",
      "       [-0.11301023,  0.04323405,  0.1764815 , ..., -0.04473288,\n",
      "         0.03915856, -0.09169532],\n",
      "       [-0.08620808,  0.10306051, -0.02595973, ..., -0.03103519,\n",
      "         0.15668765, -0.10461713],\n",
      "       ...,\n",
      "       [-0.0372523 , -0.17782448, -0.02158523, ..., -0.02616933,\n",
      "         0.1337831 ,  0.06775228],\n",
      "       [ 0.23349434,  0.00998866, -0.23397462, ..., -0.08640979,\n",
      "         0.05319152,  0.03638601],\n",
      "       [-0.04554533, -0.04104453, -0.04660714, ..., -0.119583  ,\n",
      "         0.11672503, -0.07719002]], dtype=float32)}, 'c_proj': {'b': array([ 0.10863993,  0.09696787, -0.00198932, ..., -0.02723117,\n",
      "        0.00059022,  0.04252363], dtype=float32), 'w': array([[ 0.01718313, -0.18024635,  0.18323494, ..., -0.20488226,\n",
      "         0.0312878 ,  0.11543295],\n",
      "       [-0.1892676 ,  0.02871369,  0.09538276, ...,  0.10042694,\n",
      "         0.11564773, -0.05099011],\n",
      "       [-0.08379357,  0.09560087, -0.08194933, ..., -0.17775702,\n",
      "         0.03315809,  0.25055662],\n",
      "       ...,\n",
      "       [-0.03420233, -0.07231052, -0.00445368, ..., -0.07976946,\n",
      "         0.01102673, -0.10428194],\n",
      "       [-0.05106509,  0.06967785,  0.20804296, ...,  0.00551788,\n",
      "        -0.02403912,  0.02734608],\n",
      "       [ 0.08827464,  0.02491595,  0.03697589, ...,  0.12646855,\n",
      "         0.07216249, -0.0732566 ]], dtype=float32)}}, 'ln_1': {'b': array([-0.01998281, -0.01114852, -0.01884042, ...,  0.00086737,\n",
      "       -0.00641976, -0.01010923], dtype=float32), 'g': array([0.46060088, 0.44759667, 0.43435436, ..., 0.46480492, 0.4372749 ,\n",
      "       0.45074993], dtype=float32)}, 'ln_2': {'b': array([-0.01091692,  0.02916744,  0.03071516, ...,  0.01298699,\n",
      "        0.05433188,  0.03702139], dtype=float32), 'g': array([0.387699  , 0.38491923, 0.37616947, ..., 0.39159873, 0.39997303,\n",
      "       0.37792635], dtype=float32)}, 'mlp': {'c_fc': {'b': array([ 0.00206685, -0.01423658, -0.08940957, ..., -0.08744072,\n",
      "       -0.07657272, -0.12251715], dtype=float32), 'w': array([[ 0.00690531,  0.09493607, -0.11846235, ..., -0.12912355,\n",
      "        -0.20729047, -0.11034338],\n",
      "       [-0.04689084, -0.05661451, -0.02013963, ...,  0.03530024,\n",
      "        -0.12941475, -0.07512348],\n",
      "       [-0.14711548, -0.22684455, -0.03679287, ...,  0.05635598,\n",
      "        -0.07974678,  0.00767909],\n",
      "       ...,\n",
      "       [ 0.00205888,  0.04501219, -0.04491249, ..., -0.0650923 ,\n",
      "         0.10266459,  0.10761563],\n",
      "       [ 0.02365897,  0.00760743, -0.10134775, ..., -0.0499773 ,\n",
      "        -0.14644252,  0.10302201],\n",
      "       [ 0.09001636, -0.06234408,  0.02546653, ..., -0.04053145,\n",
      "        -0.06688611, -0.05670159]], dtype=float32)}, 'c_proj': {'b': array([-0.12186442,  0.10488576,  0.07448519, ...,  0.2335394 ,\n",
      "        0.12311966,  0.01833355], dtype=float32), 'w': array([[-0.01044672,  0.01517396, -0.01404792, ...,  0.03466403,\n",
      "        -0.20203975, -0.04706684],\n",
      "       [-0.12384481,  0.08675352,  0.05580541, ..., -0.06591729,\n",
      "        -0.04596357, -0.00917706],\n",
      "       [ 0.09754276,  0.14138989, -0.09074526, ..., -0.2378039 ,\n",
      "         0.13216661,  0.10831067],\n",
      "       ...,\n",
      "       [ 0.04303049, -0.20301943, -0.09549796, ...,  0.18596752,\n",
      "         0.16074362, -0.17237303],\n",
      "       [ 0.08890822, -0.04221603,  0.05329386, ..., -0.01090272,\n",
      "         0.20314452, -0.04217653],\n",
      "       [-0.16789451, -0.08060081,  0.13753623, ...,  0.09883741,\n",
      "        -0.02579791,  0.11198758]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.0284439 ,  0.0696408 ,  0.12599646, ..., -0.0310528 ,\n",
      "        0.00216071,  0.0181042 ], dtype=float32), 'w': array([[ 0.14957666, -0.10122824, -0.12861405, ...,  0.04253074,\n",
      "         0.02043874,  0.01694059],\n",
      "       [-0.02016336, -0.06484299, -0.20537199, ..., -0.02001439,\n",
      "         0.02743563, -0.06354953],\n",
      "       [-0.06641152,  0.01360705,  0.02995203, ..., -0.13142172,\n",
      "        -0.00852925,  0.00514571],\n",
      "       ...,\n",
      "       [ 0.11690612,  0.0184038 , -0.0173052 , ..., -0.06472977,\n",
      "        -0.05709801, -0.11263286],\n",
      "       [-0.20151822, -0.06346753, -0.08967816, ...,  0.01585377,\n",
      "        -0.11605591, -0.00218614],\n",
      "       [ 0.02192801,  0.19838358, -0.18618761, ..., -0.11727072,\n",
      "         0.0087973 ,  0.04573932]], dtype=float32)}, 'c_proj': {'b': array([ 0.0085075 , -0.04732022, -0.05592938, ..., -0.1501378 ,\n",
      "       -0.12195075,  0.1657301 ], dtype=float32), 'w': array([[-0.02628032, -0.00769961,  0.08860108, ..., -0.02975239,\n",
      "         0.14549564, -0.06654979],\n",
      "       [-0.1479192 , -0.07529697, -0.00224477, ...,  0.09993631,\n",
      "        -0.02863263,  0.02514339],\n",
      "       [-0.14494522,  0.0790337 ,  0.17599246, ..., -0.14246026,\n",
      "         0.02943149, -0.10945702],\n",
      "       ...,\n",
      "       [ 0.05515418,  0.05121428,  0.03993333, ..., -0.0444768 ,\n",
      "         0.00774366, -0.08884077],\n",
      "       [ 0.01436202, -0.00827156, -0.01855968, ...,  0.03528567,\n",
      "        -0.13513047,  0.02826394],\n",
      "       [-0.04096264, -0.02853278, -0.00479752, ...,  0.03155186,\n",
      "         0.03088058, -0.01565282]], dtype=float32)}}, 'ln_1': {'b': array([-0.02139882, -0.00667061, -0.01699699, ...,  0.00546577,\n",
      "       -0.00905055, -0.01252218], dtype=float32), 'g': array([0.47393283, 0.44059014, 0.4619169 , ..., 0.4614351 , 0.43632314,\n",
      "       0.4446512 ], dtype=float32)}, 'ln_2': {'b': array([0.01389737, 0.04858163, 0.05045044, ..., 0.00899272, 0.05704829,\n",
      "       0.01047244], dtype=float32), 'g': array([0.4010841 , 0.39334568, 0.38913536, ..., 0.3910325 , 0.40385708,\n",
      "       0.37594742], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.03433287, -0.07187528,  0.0367096 , ..., -0.09427188,\n",
      "        0.05029005, -0.08224978], dtype=float32), 'w': array([[-0.12961179, -0.11446992, -0.02763129, ...,  0.05356323,\n",
      "        -0.02515784, -0.0447014 ],\n",
      "       [-0.08799062,  0.03767316, -0.00133413, ...,  0.02340684,\n",
      "        -0.1499115 , -0.00083202],\n",
      "       [-0.03142789, -0.07688143, -0.07053981, ..., -0.07253864,\n",
      "         0.05178915, -0.10986447],\n",
      "       ...,\n",
      "       [-0.09870277,  0.1490455 ,  0.14206032, ..., -0.00676655,\n",
      "         0.0043229 , -0.0016061 ],\n",
      "       [ 0.08338383, -0.04182887, -0.05274976, ..., -0.20334572,\n",
      "        -0.03028126, -0.21844885],\n",
      "       [-0.09286522, -0.01967975,  0.00798633, ..., -0.03251693,\n",
      "        -0.0178849 ,  0.03430393]], dtype=float32)}, 'c_proj': {'b': array([-0.0720937 ,  0.03637735, -0.03421617, ...,  0.20800315,\n",
      "        0.04170598,  0.06457108], dtype=float32), 'w': array([[ 0.05346724, -0.19839397,  0.04797305, ..., -0.03469186,\n",
      "         0.09413362,  0.00378306],\n",
      "       [ 0.07243591, -0.18579881, -0.04019627, ..., -0.03295082,\n",
      "         0.25346664, -0.043356  ],\n",
      "       [ 0.10936212,  0.16200219,  0.11714657, ...,  0.0297803 ,\n",
      "         0.08718013, -0.04297658],\n",
      "       ...,\n",
      "       [-0.03443351, -0.25256273, -0.0437615 , ..., -0.1268942 ,\n",
      "         0.08414258, -0.03402703],\n",
      "       [-0.07158689,  0.1499416 , -0.10427357, ..., -0.06791425,\n",
      "        -0.0602858 ,  0.20865701],\n",
      "       [ 0.19446048,  0.06465898, -0.16268808, ..., -0.07517808,\n",
      "        -0.08487561, -0.11200023]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([-0.08693713,  0.06923026, -0.00791926, ...,  0.01799437,\n",
      "        0.00500376, -0.07353536], dtype=float32), 'w': array([[-0.04061288, -0.05515226, -0.03927361, ...,  0.09609822,\n",
      "        -0.03334925,  0.07250515],\n",
      "       [-0.01167772, -0.01260844,  0.08084407, ..., -0.06663997,\n",
      "        -0.03934668,  0.03012883],\n",
      "       [-0.13246115, -0.17550135, -0.05240173, ...,  0.00993536,\n",
      "        -0.04120851, -0.14108065],\n",
      "       ...,\n",
      "       [-0.01231142,  0.19719666, -0.1614498 , ...,  0.14057527,\n",
      "        -0.06218328,  0.08153196],\n",
      "       [-0.06355638, -0.02113467, -0.04611881, ...,  0.1004068 ,\n",
      "         0.08444118,  0.14328538],\n",
      "       [ 0.15376505,  0.02819451,  0.29078385, ..., -0.03745652,\n",
      "         0.06082195, -0.12432714]], dtype=float32)}, 'c_proj': {'b': array([ 0.02395684,  0.0220874 ,  0.04416773, ..., -0.22139846,\n",
      "       -0.05703462,  0.06012116], dtype=float32), 'w': array([[-0.05108322, -0.03852792, -0.13546534, ...,  0.08056195,\n",
      "         0.08688046, -0.05754481],\n",
      "       [-0.07082133,  0.03161674,  0.01189771, ..., -0.11683133,\n",
      "         0.0661781 , -0.09524338],\n",
      "       [-0.04985178,  0.03575264, -0.0091233 , ..., -0.08410694,\n",
      "         0.02710165,  0.05526277],\n",
      "       ...,\n",
      "       [ 0.00421171,  0.10998277, -0.10716778, ...,  0.01505122,\n",
      "        -0.00876353,  0.16036813],\n",
      "       [ 0.00289799,  0.08322901, -0.14599146, ...,  0.1657047 ,\n",
      "         0.1990874 , -0.1611498 ],\n",
      "       [ 0.3521733 , -0.07217092, -0.08776564, ..., -0.04481336,\n",
      "         0.0365552 ,  0.00490154]], dtype=float32)}}, 'ln_1': {'b': array([-0.02329385, -0.00680508, -0.01613497, ...,  0.00078715,\n",
      "       -0.01204995, -0.00860678], dtype=float32), 'g': array([0.50966483, 0.47145626, 0.4937451 , ..., 0.4873114 , 0.47541922,\n",
      "       0.48357475], dtype=float32)}, 'ln_2': {'b': array([0.02233466, 0.05382935, 0.04490197, ..., 0.00326878, 0.06873468,\n",
      "       0.00935039], dtype=float32), 'g': array([0.4223952 , 0.4188015 , 0.40473756, ..., 0.40722936, 0.42054117,\n",
      "       0.4003894 ], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.11756147, -0.05193475, -0.06473382, ..., -0.00387246,\n",
      "        0.13187368, -0.0804345 ], dtype=float32), 'w': array([[-0.13628756,  0.11284378, -0.01050432, ..., -0.04420264,\n",
      "        -0.04645136, -0.03729547],\n",
      "       [-0.02594072, -0.02039799, -0.0151359 , ..., -0.10270394,\n",
      "        -0.01606529,  0.03545125],\n",
      "       [ 0.16275692, -0.01681374, -0.28825286, ..., -0.17783563,\n",
      "        -0.06247073, -0.17445524],\n",
      "       ...,\n",
      "       [-0.07302837,  0.03871817,  0.09766058, ...,  0.1682518 ,\n",
      "        -0.01596448, -0.1284967 ],\n",
      "       [ 0.05139764, -0.08654768, -0.23186632, ..., -0.04810672,\n",
      "        -0.07067342, -0.1770228 ],\n",
      "       [ 0.00298558,  0.01102898, -0.00385471, ..., -0.00282606,\n",
      "        -0.1263278 , -0.04453284]], dtype=float32)}, 'c_proj': {'b': array([-0.02918543,  0.02145462, -0.04164769, ...,  0.1948249 ,\n",
      "        0.07172404,  0.00209988], dtype=float32), 'w': array([[-0.01840211, -0.14770885, -0.04801126, ...,  0.05956686,\n",
      "        -0.24085745,  0.24202614],\n",
      "       [-0.2547699 ,  0.05615184,  0.1613982 , ...,  0.14846434,\n",
      "        -0.12240186,  0.09421431],\n",
      "       [-0.07423896, -0.22018299,  0.38188055, ...,  0.02724741,\n",
      "         0.03404763,  0.08105875],\n",
      "       ...,\n",
      "       [ 0.1059049 ,  0.0890462 ,  0.08160394, ..., -0.03505136,\n",
      "        -0.1868482 , -0.33005428],\n",
      "       [-0.09169031, -0.1265216 , -0.07248366, ...,  0.07017252,\n",
      "         0.08929965, -0.07428491],\n",
      "       [-0.0632982 ,  0.03455748, -0.06287467, ...,  0.08503827,\n",
      "         0.05374696,  0.09692479]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([-0.01459546, -0.03990439,  0.01992324, ...,  0.00308884,\n",
      "        0.01416642, -0.01577165], dtype=float32), 'w': array([[ 2.0485997e-02, -1.2868655e-02, -1.5261218e-01, ...,\n",
      "        -2.3241048e-01,  4.0329276e-03, -7.6454163e-02],\n",
      "       [-7.6576829e-02, -1.2451114e-01, -4.2837965e-03, ...,\n",
      "        -2.0523082e-02, -1.5489770e-03, -2.3938024e-02],\n",
      "       [-6.0800429e-02, -1.0595188e-02, -1.5909351e-01, ...,\n",
      "         1.4832380e-01, -1.9871013e-01, -6.8983577e-02],\n",
      "       ...,\n",
      "       [-5.2662466e-02, -8.8253573e-02,  4.7090087e-02, ...,\n",
      "         1.1910594e-01,  6.9783635e-02, -1.1972273e-01],\n",
      "       [ 3.8925293e-03, -1.1362140e-01,  3.4106880e-02, ...,\n",
      "         1.4228910e-01, -1.3310619e-01,  9.2895277e-02],\n",
      "       [-1.2707799e-02, -1.4126405e-01,  3.6266144e-02, ...,\n",
      "        -1.1302298e-01,  1.2007335e-01,  1.8969951e-04]], dtype=float32)}, 'c_proj': {'b': array([ 0.1367824 , -0.00685308,  0.12722611, ..., -0.21129666,\n",
      "       -0.08296065,  0.04951794], dtype=float32), 'w': array([[ 0.12522142, -0.15966061,  0.3060781 , ..., -0.09662122,\n",
      "         0.1709281 ,  0.182625  ],\n",
      "       [ 0.07696419, -0.04816192,  0.1090036 , ..., -0.06640691,\n",
      "        -0.02682208,  0.1244584 ],\n",
      "       [ 0.23837678, -0.05151967,  0.01179054, ...,  0.13086003,\n",
      "        -0.1159957 , -0.00481023],\n",
      "       ...,\n",
      "       [-0.13827588,  0.10764156,  0.02303287, ...,  0.02264617,\n",
      "         0.08468895, -0.07525962],\n",
      "       [-0.10895618, -0.00365709,  0.01757344, ...,  0.0263429 ,\n",
      "        -0.09083126,  0.04083446],\n",
      "       [-0.02072269, -0.02484934, -0.18258648, ..., -0.072969  ,\n",
      "        -0.1561066 ,  0.02341298]], dtype=float32)}}, 'ln_1': {'b': array([-0.03494756, -0.01264444, -0.01645493, ...,  0.00470497,\n",
      "       -0.00144972, -0.0055947 ], dtype=float32), 'g': array([0.5143984 , 0.48387733, 0.5144926 , ..., 0.49779153, 0.4889851 ,\n",
      "       0.4853228 ], dtype=float32)}, 'ln_2': {'b': array([ 0.01309927,  0.03215595,  0.04592702, ..., -0.00310279,\n",
      "        0.07115997,  0.01753556], dtype=float32), 'g': array([0.45563486, 0.42578554, 0.4418617 , ..., 0.44668043, 0.45448658,\n",
      "       0.43065688], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.06806697, -0.04783952, -0.1157781 , ..., -0.07982605,\n",
      "       -0.06042016, -0.05652412], dtype=float32), 'w': array([[ 0.17959917, -0.03750777,  0.00340636, ...,  0.06478614,\n",
      "         0.16096303, -0.04218293],\n",
      "       [-0.06856064,  0.02521326, -0.0325564 , ..., -0.03350404,\n",
      "        -0.04788196,  0.02125955],\n",
      "       [-0.10349062,  0.05658519,  0.1431919 , ..., -0.14973433,\n",
      "         0.00797699,  0.05118499],\n",
      "       ...,\n",
      "       [ 0.01125765, -0.06281164,  0.05417668, ...,  0.00694695,\n",
      "         0.09098231, -0.11531855],\n",
      "       [-0.1284483 , -0.02112247,  0.13421558, ..., -0.02118107,\n",
      "         0.08926027,  0.00169987],\n",
      "       [-0.06215852,  0.0538927 , -0.08509022, ..., -0.02394915,\n",
      "        -0.00196809,  0.16458735]], dtype=float32)}, 'c_proj': {'b': array([ 0.0648478 , -0.09947827,  0.00924565, ...,  0.12382776,\n",
      "        0.03355823,  0.0305949 ], dtype=float32), 'w': array([[-0.12595192, -0.1708308 ,  0.02862717, ...,  0.30036685,\n",
      "        -0.18549456, -0.1166371 ],\n",
      "       [ 0.07515022, -0.01527612, -0.16720916, ..., -0.03647318,\n",
      "         0.13579932,  0.17433266],\n",
      "       [-0.10376533,  0.13450582, -0.08544961, ..., -0.21829563,\n",
      "        -0.17103213,  0.16807725],\n",
      "       ...,\n",
      "       [ 0.01566309,  0.01893311,  0.04352034, ..., -0.291327  ,\n",
      "         0.12885235,  0.24976498],\n",
      "       [-0.06080827, -0.03723683, -0.00351037, ..., -0.11177525,\n",
      "         0.05031507, -0.03412384],\n",
      "       [ 0.19263776,  0.22014235, -0.03945401, ...,  0.19927225,\n",
      "         0.00098866, -0.1298591 ]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([-0.05847308, -0.00769529,  0.5258212 , ..., -0.01590991,\n",
      "       -0.05061242,  0.03858395], dtype=float32), 'w': array([[ 0.11739084, -0.09666298, -0.2982143 , ...,  0.00471266,\n",
      "        -0.06011533, -0.05273808],\n",
      "       [-0.15720627,  0.07679277, -0.14414465, ...,  0.06318473,\n",
      "        -0.00883456, -0.19411159],\n",
      "       [ 0.00768238, -0.00883551, -0.10120131, ..., -0.3179096 ,\n",
      "        -0.05760198, -0.00125955],\n",
      "       ...,\n",
      "       [ 0.00339669,  0.00736353, -0.01357946, ..., -0.18899193,\n",
      "        -0.31733996,  0.02221889],\n",
      "       [ 0.01685764, -0.14865617,  0.10514215, ..., -0.16263267,\n",
      "         0.17438139, -0.15558828],\n",
      "       [ 0.00788452, -0.02486846, -0.12107021, ..., -0.01796106,\n",
      "        -0.17749576,  0.00283783]], dtype=float32)}, 'c_proj': {'b': array([ 0.12513876, -0.06110018,  0.00451837, ..., -0.15259841,\n",
      "       -0.04431348,  0.14357874], dtype=float32), 'w': array([[-0.14079247,  0.21008977,  0.00045529, ..., -0.04844258,\n",
      "         0.04194739,  0.00765531],\n",
      "       [ 0.07392211, -0.05448431, -0.08070583, ...,  0.06944108,\n",
      "        -0.10535745, -0.1283246 ],\n",
      "       [ 0.04602849,  0.00985119, -0.00636537, ..., -0.0506771 ,\n",
      "        -0.07901815, -0.17722003],\n",
      "       ...,\n",
      "       [ 0.04809498, -0.13607366,  0.26867193, ...,  0.22429198,\n",
      "         0.12151098, -0.05951772],\n",
      "       [-0.00957354, -0.0311547 , -0.19885567, ...,  0.2380868 ,\n",
      "         0.21503054, -0.24654315],\n",
      "       [ 0.02507307,  0.08268822,  0.01411157, ..., -0.02910641,\n",
      "         0.06470445, -0.01380459]], dtype=float32)}}, 'ln_1': {'b': array([-0.02927737, -0.00435225, -0.0146479 , ...,  0.00726298,\n",
      "       -0.00612681, -0.01181168], dtype=float32), 'g': array([0.5734406 , 0.51566756, 0.5449584 , ..., 0.5471623 , 0.52959573,\n",
      "       0.54102355], dtype=float32)}, 'ln_2': {'b': array([ 0.01499533,  0.0180941 ,  0.04902596, ..., -0.00124834,\n",
      "        0.04267803,  0.01007139], dtype=float32), 'g': array([0.49120417, 0.4578422 , 0.49106836, ..., 0.48382148, 0.4844312 ,\n",
      "       0.46667895], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.08409852, -0.11263594,  0.05041247, ..., -0.075748  ,\n",
      "       -0.07044153, -0.0521343 ], dtype=float32), 'w': array([[-6.95366710e-02,  5.64022502e-03, -5.38844056e-02, ...,\n",
      "         1.40616611e-01, -5.46424836e-02, -9.12358891e-03],\n",
      "       [ 7.39389434e-02,  2.36611813e-02, -7.99329653e-02, ...,\n",
      "         1.48907378e-01, -2.73806844e-02,  3.48116122e-02],\n",
      "       [ 9.90091860e-02,  6.76022619e-02,  2.26401575e-02, ...,\n",
      "         1.48890633e-02, -2.29791939e-01, -1.22423068e-01],\n",
      "       ...,\n",
      "       [ 2.98682824e-02,  7.95594230e-02, -3.83058973e-02, ...,\n",
      "        -1.07482761e-01,  4.19693552e-02, -6.80924580e-02],\n",
      "       [-2.16478598e-04, -5.32379597e-02,  1.03249654e-01, ...,\n",
      "         3.15301828e-02, -8.72083679e-02,  1.62515882e-02],\n",
      "       [ 4.51476239e-02, -1.43262044e-01,  6.47971258e-02, ...,\n",
      "         1.31477028e-01,  5.09571582e-02, -1.53406054e-01]], dtype=float32)}, 'c_proj': {'b': array([ 0.05748913, -0.08024952, -0.05904538, ...,  0.05806364,\n",
      "        0.12378316, -0.02766007], dtype=float32), 'w': array([[ 0.22770633, -0.05576285,  0.19710687, ...,  0.11212085,\n",
      "        -0.01157583,  0.02973633],\n",
      "       [-0.16758509,  0.3146123 ,  0.09790298, ..., -0.12205604,\n",
      "         0.1613705 ,  0.00660508],\n",
      "       [ 0.1837717 ,  0.04843522, -0.01772129, ..., -0.1229767 ,\n",
      "        -0.02353011,  0.11056381],\n",
      "       ...,\n",
      "       [ 0.0528822 ,  0.04869321, -0.15311703, ...,  0.08941724,\n",
      "        -0.19694783,  0.24340047],\n",
      "       [ 0.00536864,  0.2382295 , -0.24578045, ..., -0.033627  ,\n",
      "        -0.0331777 , -0.17419918],\n",
      "       [ 0.12589973, -0.03452034, -0.13132735, ...,  0.11999317,\n",
      "        -0.23358648, -0.2045771 ]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([ 0.03633153, -0.02089597, -0.10776677, ..., -0.00036164,\n",
      "       -0.19063133, -0.01390907], dtype=float32), 'w': array([[ 0.15714401, -0.12207418,  0.03142342, ..., -0.0085085 ,\n",
      "        -0.02370706, -0.0565839 ],\n",
      "       [-0.12682553, -0.21514055,  0.09807289, ..., -0.16470858,\n",
      "        -0.04686034, -0.04947569],\n",
      "       [ 0.01014266, -0.03370715, -0.17743543, ..., -0.18680818,\n",
      "         0.06116908, -0.07489005],\n",
      "       ...,\n",
      "       [-0.12424482,  0.09674224, -0.2140257 , ..., -0.13248096,\n",
      "        -0.10597117,  0.02464369],\n",
      "       [ 0.02341061, -0.10858931, -0.12236139, ..., -0.03628423,\n",
      "        -0.03795186,  0.039323  ],\n",
      "       [ 0.09021898,  0.06931657, -0.10398708, ...,  0.02392999,\n",
      "         0.09143442,  0.08013763]], dtype=float32)}, 'c_proj': {'b': array([ 0.07101437,  0.05577097,  0.04441731, ..., -0.11561465,\n",
      "        0.00062518,  0.05038352], dtype=float32), 'w': array([[-0.1996403 , -0.13568373,  0.1647483 , ..., -0.029432  ,\n",
      "        -0.04935483, -0.0162105 ],\n",
      "       [ 0.02984073, -0.03072774,  0.09680316, ...,  0.21487202,\n",
      "         0.08280339, -0.02505386],\n",
      "       [-0.06078079,  0.06042272,  0.18098594, ...,  0.12776577,\n",
      "         0.06113567, -0.1314198 ],\n",
      "       ...,\n",
      "       [-0.12444735, -0.01003399, -0.02436689, ...,  0.11899413,\n",
      "        -0.16974373, -0.02455212],\n",
      "       [ 0.08094497, -0.03237863, -0.06282468, ..., -0.17696193,\n",
      "        -0.07680806,  0.01541525],\n",
      "       [-0.03650485, -0.00913525, -0.30053034, ...,  0.03156149,\n",
      "         0.280056  ,  0.15803495]], dtype=float32)}}, 'ln_1': {'b': array([-4.8268881e-02, -3.8822424e-03, -4.1070236e-03, ...,\n",
      "        5.0385174e-04, -8.3622454e-06, -1.8132720e-02], dtype=float32), 'g': array([0.6630937 , 0.5974894 , 0.64720654, ..., 0.60778964, 0.61523145,\n",
      "       0.63869274], dtype=float32)}, 'ln_2': {'b': array([0.01696189, 0.03187172, 0.01116186, ..., 0.00908761, 0.04868009,\n",
      "       0.02439043], dtype=float32), 'g': array([0.572251 , 0.5409504, 0.5643399, ..., 0.570044 , 0.5679076,\n",
      "       0.5527348], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.06050253, -0.04391648,  0.00697862, ..., -0.06629884,\n",
      "       -0.10342849, -0.06454865], dtype=float32), 'w': array([[ 0.0591711 , -0.06533475,  0.16084433, ..., -0.0320065 ,\n",
      "         0.08300447,  0.1248271 ],\n",
      "       [ 0.16528727, -0.1418334 ,  0.10793258, ..., -0.11158565,\n",
      "         0.08048145, -0.00045602],\n",
      "       [-0.0634544 , -0.01249727,  0.04273359, ...,  0.10122257,\n",
      "         0.17942375,  0.0494419 ],\n",
      "       ...,\n",
      "       [ 0.15497033, -0.00889488, -0.04557162, ...,  0.19789743,\n",
      "         0.14997427, -0.04594667],\n",
      "       [-0.15699671,  0.03219492, -0.04408622, ..., -0.00995749,\n",
      "        -0.10788454, -0.07148019],\n",
      "       [ 0.02297616, -0.16422383,  0.0110186 , ...,  0.02630433,\n",
      "         0.02440769,  0.06281229]], dtype=float32)}, 'c_proj': {'b': array([ 0.05623831, -0.08885086, -0.11938067, ...,  0.12789375,\n",
      "        0.00592295,  0.0340883 ], dtype=float32), 'w': array([[ 0.06705303,  0.04172666, -0.10010397, ..., -0.05181934,\n",
      "        -0.16241966,  0.11514659],\n",
      "       [-0.12289352, -0.09165683,  0.02189313, ...,  0.03843011,\n",
      "         0.31949425, -0.05215855],\n",
      "       [-0.01911397, -0.22611223, -0.10786486, ..., -0.12916517,\n",
      "        -0.19392532, -0.00386401],\n",
      "       ...,\n",
      "       [ 0.21354572, -0.03985064, -0.02084631, ..., -0.08567762,\n",
      "         0.00966908,  0.04201885],\n",
      "       [-0.20876148, -0.00888804, -0.00145163, ...,  0.06669891,\n",
      "        -0.03446012, -0.04281811],\n",
      "       [-0.05118359,  0.02100468,  0.06697843, ..., -0.07854089,\n",
      "         0.10437338,  0.06055886]], dtype=float32)}}}, {'attn': {'c_attn': {'b': array([-0.00326422,  0.08844039,  0.00673814, ..., -0.0061976 ,\n",
      "        0.00410593, -0.02023612], dtype=float32), 'w': array([[-0.01960574, -0.1935276 , -0.20473401, ..., -0.10147403,\n",
      "        -0.01450329, -0.161951  ],\n",
      "       [-0.06095712,  0.11501715,  0.08203499, ..., -0.18588983,\n",
      "         0.12908503,  0.09816743],\n",
      "       [ 0.08322848,  0.0912342 , -0.01059629, ...,  0.15860361,\n",
      "         0.11799045,  0.22903323],\n",
      "       ...,\n",
      "       [ 0.15412633,  0.11625916,  0.14075881, ...,  0.07658532,\n",
      "        -0.15059523, -0.09844759],\n",
      "       [ 0.12280138,  0.03327154, -0.04118696, ..., -0.06903221,\n",
      "         0.0103437 ,  0.11368339],\n",
      "       [ 0.15847006, -0.03339333,  0.11640354, ...,  0.20501176,\n",
      "         0.07984929,  0.0574111 ]], dtype=float32)}, 'c_proj': {'b': array([-0.0694735 , -0.10479602,  0.09334961, ..., -0.00079619,\n",
      "        0.1336612 ,  0.07665779], dtype=float32), 'w': array([[-0.03531378, -0.18908334,  0.22720966, ..., -0.31022742,\n",
      "        -0.05674075,  0.40641427],\n",
      "       [ 0.11008526,  0.17983669, -0.23547256, ..., -0.06675495,\n",
      "         0.04579863,  0.21610707],\n",
      "       [ 0.09389434, -0.09454823,  0.04973679, ..., -0.07224023,\n",
      "        -0.07671156, -0.02159943],\n",
      "       ...,\n",
      "       [ 0.08240509, -0.01329114, -0.11288242, ...,  0.02381241,\n",
      "        -0.06771473, -0.04323152],\n",
      "       [-0.10296056,  0.0028607 , -0.00860632, ...,  0.03791198,\n",
      "        -0.08938865,  0.0160298 ],\n",
      "       [-0.04293731, -0.02587449, -0.01748761, ..., -0.00765462,\n",
      "        -0.02250004,  0.16424689]], dtype=float32)}}, 'ln_1': {'b': array([-0.02112646,  0.02171666,  0.0021225 , ...,  0.03277574,\n",
      "        0.02219068, -0.00027753], dtype=float32), 'g': array([0.73042935, 0.70137495, 0.73240036, ..., 0.73260605, 0.73667383,\n",
      "       0.7487238 ], dtype=float32)}, 'ln_2': {'b': array([-0.00586556,  0.05381727,  0.00201045, ...,  0.00605759,\n",
      "        0.02084465, -0.00244322], dtype=float32), 'g': array([0.6883303 , 0.650366  , 0.6668272 , ..., 0.7015477 , 0.67746395,\n",
      "       0.65021026], dtype=float32)}, 'mlp': {'c_fc': {'b': array([-0.00215542, -0.04396905,  0.11996928, ..., -0.16288602,\n",
      "        0.02494142,  0.01763427], dtype=float32), 'w': array([[ 0.00096057, -0.05026902,  0.2704816 , ...,  0.02676428,\n",
      "         0.06314981,  0.12221805],\n",
      "       [-0.02115238, -0.03308024,  0.04259997, ..., -0.08804061,\n",
      "        -0.01175216, -0.12605305],\n",
      "       [ 0.04133447,  0.18654619, -0.23351829, ...,  0.07970451,\n",
      "         0.07561996, -0.04417238],\n",
      "       ...,\n",
      "       [ 0.08812102, -0.13380498, -0.0851962 , ..., -0.143215  ,\n",
      "         0.26304126,  0.04053133],\n",
      "       [-0.15843986, -0.1630559 ,  0.094303  , ..., -0.16813208,\n",
      "        -0.03787546,  0.07793044],\n",
      "       [ 0.18809244, -0.10469681, -0.12028316, ..., -0.11872222,\n",
      "         0.15671195, -0.03802427]], dtype=float32)}, 'c_proj': {'b': array([-0.01200422,  0.04088693,  0.09540925, ..., -0.06556628,\n",
      "        0.03649034,  0.04745885], dtype=float32), 'w': array([[ 0.31255186, -0.16338316,  0.12430195, ...,  0.00836221,\n",
      "         0.04987115,  0.22657508],\n",
      "       [ 0.20409933, -0.02055959,  0.02072912, ...,  0.17527181,\n",
      "         0.20649321, -0.0455978 ],\n",
      "       [-0.08122641,  0.01853926,  0.25442708, ...,  0.15123822,\n",
      "        -0.15992172, -0.17434105],\n",
      "       ...,\n",
      "       [ 0.05406858, -0.03922641, -0.2793093 , ...,  0.35302192,\n",
      "         0.26924193, -0.06148095],\n",
      "       [ 0.14695849,  0.0346247 ,  0.02367792, ..., -0.05960982,\n",
      "        -0.15347724,  0.10440313],\n",
      "       [-0.08630804, -0.01672608,  0.01255768, ...,  0.4254069 ,\n",
      "         0.05639928,  0.05509165]], dtype=float32)}}}], 'b': array([ 0.12569863,  0.11785158,  0.09613176, ..., -0.02183932,\n",
      "        0.06012571,  0.06370714], dtype=float32), 'g': array([1.5125406, 1.5389119, 1.6752999, ..., 1.5353073, 1.6314863,\n",
      "       1.5572528], dtype=float32), 'wpe': array([[-0.03718615, -0.0033882 , -0.02236843, ..., -0.00266328,\n",
      "         0.00515606, -0.00300787],\n",
      "       [ 0.03726007, -0.01787332, -0.01440073, ...,  0.023228  ,\n",
      "        -0.00377229,  0.00699384],\n",
      "       [-0.00173793, -0.02259352,  0.01792418, ...,  0.01958712,\n",
      "         0.02206792, -0.01403322],\n",
      "       ...,\n",
      "       [ 0.00045834, -0.00692104,  0.00174784, ...,  0.00203879,\n",
      "         0.00039957,  0.01589834],\n",
      "       [-0.00322849, -0.00329247,  0.00109231, ...,  0.00360864,\n",
      "        -0.00454369,  0.01792836],\n",
      "       [-0.00639096,  0.0078875 , -0.00102477, ..., -0.00398669,\n",
      "        -0.00109838, -0.00149736]], dtype=float32), 'wte': array([[-0.0115168 ,  0.00311915, -0.00729894, ..., -0.05262156,\n",
      "        -0.17569277,  0.02565791],\n",
      "       [-0.00861426,  0.06360211, -0.01822355, ..., -0.01364703,\n",
      "        -0.12153847,  0.05352487],\n",
      "       [ 0.05854857,  0.06891199,  0.02622696, ..., -0.10057542,\n",
      "        -0.19788682, -0.0039184 ],\n",
      "       ...,\n",
      "       [ 0.00162342, -0.04411932, -0.0517492 , ..., -0.10079621,\n",
      "        -0.00865952,  0.02637872],\n",
      "       [-0.14374605, -0.04632217, -0.00650705, ...,  0.07464293,\n",
      "        -0.04721651, -0.03829013],\n",
      "       [ 0.02065966, -0.01334631, -0.02586888, ...,  0.03886637,\n",
      "        -0.00233481,  0.00107106]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b10912fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0115168   0.00311915 -0.00729894 ... -0.05262156 -0.17569277\n",
      "   0.02565791]\n",
      " [-0.00861426  0.06360211 -0.01822355 ... -0.01364703 -0.12153847\n",
      "   0.05352487]\n",
      " [ 0.05854857  0.06891199  0.02622696 ... -0.10057542 -0.19788682\n",
      "  -0.0039184 ]\n",
      " ...\n",
      " [ 0.00162342 -0.04411932 -0.0517492  ... -0.10079621 -0.00865952\n",
      "   0.02637872]\n",
      " [-0.14374605 -0.04632217 -0.00650705 ...  0.07464293 -0.04721651\n",
      "  -0.03829013]\n",
      " [ 0.02065966 -0.01334631 -0.02586888 ...  0.03886637 -0.00233481\n",
      "   0.00107106]]\n",
      "Token embedding weight tensor dimensions: (50257, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5c10affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "model_name = \"gpt2-medium (355M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c7282b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "925de964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "266492c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    " if left.shape != right.shape:\n",
    "    raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "    \"Right: {right.shape}\"\n",
    "    )\n",
    " return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "07b677fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the openai weights in the our gpt architecture\n",
    "\n",
    "import numpy as np\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "        (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].attn.W_query.weight = assign(\n",
    "        gpt.trf_blocks[b].attn.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].attn.W_key.weight = assign(\n",
    "        gpt.trf_blocks[b].attn.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].attn.W_value.weight = assign(\n",
    "        gpt.trf_blocks[b].attn.W_value.weight, v_w.T)\n",
    "        q_b, k_b, v_b = np.split(\n",
    "        (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].attn.W_query.bias = assign(\n",
    "        gpt.trf_blocks[b].attn.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].attn.W_key.bias = assign(\n",
    "        gpt.trf_blocks[b].attn.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].attn.W_value.bias = assign(\n",
    "        gpt.trf_blocks[b].attn.W_value.bias, v_b)\n",
    "        gpt.trf_blocks[b].attn.out_proj.weight = assign(\n",
    "        gpt.trf_blocks[b].attn.out_proj.weight,\n",
    "        params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].attn.out_proj.bias = assign(\n",
    "        gpt.trf_blocks[b].attn.out_proj.bias,\n",
    "        params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "        params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "        params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "        params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "        params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "        gpt.trf_blocks[b].norm1.scale,\n",
    "        params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "        gpt.trf_blocks[b].norm1.shift,\n",
    "        params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "        gpt.trf_blocks[b].norm2.scale,\n",
    "        params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "        gpt.trf_blocks[b].norm2.shift,\n",
    "        params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d4b8f50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f61c6305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward balance.\" But it seems quite different at any speed or type of energy.\n",
      "\n",
      "If you're trying to get energy\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    " model=gpt,\n",
    " idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    " max_new_tokens=25,\n",
    " context_size=NEW_CONFIG[\"context_length\"],\n",
    " top_k=50,\n",
    " temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5329bc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataloader: 9\n",
      "Length of dataloader: 1\n",
      "Training loss: 0.39402374625205994\n",
      "Validation loss: 6.527970790863037\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader , model , device)\n",
    "    val_loss = calc_loss_loader(val_loader , model , device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df277b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
