{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321dcf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "def download_and_unzip_spam_data(\n",
    "    url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download \"\n",
    "        \"and extraction.\"\n",
    "        )\n",
    "        return\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc6ca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dfbff2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\n",
    " data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"]\n",
    ")\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd31e069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14200bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
    "        num_spam, random_state=123\n",
    "    )\n",
    "    balanced_df = pd.concat([\n",
    "        ham_subset, df[df[\"Label\"] == \"spam\"]\n",
    "    ])\n",
    "    return balanced_df\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca14e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "596075f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(\n",
    "    frac=1, random_state=123\n",
    "    ).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(\n",
    "balanced_df, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d1c100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4221565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed678ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c85af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpamDataset(\n",
    " csv_file=\"train.csv\",\n",
    " max_length=None,\n",
    " tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "455dfc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    " csv_file=\"validation.csv\",\n",
    " max_length=train_dataset.max_length,\n",
    " tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    " csv_file=\"test.csv\",\n",
    " max_length=train_dataset.max_length,\n",
    " tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d77d7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a6abcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    " pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb28a3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94b5bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce339e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    " \"vocab_size\": 50257,\n",
    " \"context_length\": 1024,\n",
    " \"drop_rate\": 0.0,\n",
    " \"qkv_bias\": True\n",
    "}\n",
    "model_configs = {\n",
    " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28183a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from gpt_architecture import GPTModel, load_weights_into_gpt\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    " model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cabd371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from gpt_generator import generate_text_simple , text_to_token_ids , token_ids_to_text\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    " model=model,\n",
    " idx=text_to_token_ids(text_1, tokenizer),\n",
    " max_new_tokens=15,\n",
    " context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c613fa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    " \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    " \" 'You are a winner you have been specially\"\n",
    " \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    " model=model,\n",
    " idx=text_to_token_ids(text_2, tokenizer),\n",
    " max_new_tokens=23,\n",
    " context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f75ac0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce29adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    " in_features=BASE_CONFIG[\"emb_dim\"],\n",
    " out_features=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d149959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    " param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    " param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13e2f705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3c70808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    " outputs = model(inputs)\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58bfcd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d5b53f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(\n",
    " train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(\n",
    " val_loader, model, device, num_batches=10\n",
    ")\n",
    "test_accuracy = calc_accuracy_loader(\n",
    " test_loader, model, device, num_batches=10\n",
    ")\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ef03414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch , target_batch , model , device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)[:,-1,:]\n",
    "    loss = torch.nn.functional.cross_entropy(logits , target_batch)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "077bb256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "949065e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "    train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46303a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0]  # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abe07071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 2.29 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = \\\n",
    "    train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50,\n",
    "    eval_iter=5\n",
    " )\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30b28564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_values(\n",
    "    epochs_seen, examples_seen, train_values, val_values,\n",
    "    label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(\n",
    "    epochs_seen, val_values, linestyle=\"-.\",\n",
    "    label=f\"Validation {label}\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2144e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a15cfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(\n",
    "    text, model, tokenizer, device, max_length=None,\n",
    "    pad_token_id=50256):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "    input_ids = input_ids[:min(\n",
    "        max_length, supported_context_length\n",
    "        )]\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "\n",
    "    input_tensor = torch.tensor(\n",
    "        input_ids, device=device\n",
    "    ).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f1ef1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    " \"You are a winner you have been specially\"\n",
    " \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "print(classify_review(\n",
    " text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bfe15c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    " \"Hey, just wanted to check if we're still on\"\n",
    " \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "print(classify_review(\n",
    " text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dacdff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b3817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
